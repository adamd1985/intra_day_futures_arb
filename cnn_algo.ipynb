{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1036ad0",
   "metadata": {
    "_cell_guid": "143f9c02-8d86-484a-b4c2-eb1317289f2a",
    "_uuid": "068dcfb3-c368-468d-8410-aea88bc0b181",
    "id": "oaDoHbxVH0CW",
    "papermill": {
     "duration": 0.007734,
     "end_time": "2024-06-01T21:47:52.207387",
     "exception": false,
     "start_time": "2024-06-01T21:47:52.199653",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bbc8ec",
   "metadata": {
    "_cell_guid": "b5ba98a0-9590-4ccd-b238-cfae63d19770",
    "_uuid": "6a6076dd-8ce5-47e2-8913-74dcaa2eacf0",
    "id": "z_cBqdYOoY5S",
    "papermill": {
     "duration": 0.006911,
     "end_time": "2024-06-01T21:47:52.221485",
     "exception": false,
     "start_time": "2024-06-01T21:47:52.214574",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Notebook's Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d45818",
   "metadata": {
    "_cell_guid": "44c8b09f-6f40-410d-aa3c-89b119fb2456",
    "_uuid": "56c0c199-418e-4fa2-a71a-30d54c3a8b2c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-01T21:47:52.236731Z",
     "iopub.status.busy": "2024-06-01T21:47:52.236435Z",
     "iopub.status.idle": "2024-06-01T21:50:26.008610Z",
     "shell.execute_reply": "2024-06-01T21:50:26.007353Z"
    },
    "id": "eETPYJLiMU-b",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "49f77cf0-e6a3-44d8-9dae-05a929fa4804",
    "papermill": {
     "duration": 153.78285,
     "end_time": "2024-06-01T21:50:26.011336",
     "exception": false,
     "start_time": "2024-06-01T21:47:52.228486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "INSTALL_DEPS = True\n",
    "if INSTALL_DEPS:\n",
    "    %pip install hurst==0.0.5\n",
    "    %pip install imbalanced_learn==0.12.3\n",
    "    %pip install imblearn==0.0\n",
    "    %pip install protobuf==5.27.0\n",
    "    %pip install pykalman==0.9.7\n",
    "    %pip install tqdm==4.66.4\n",
    "    %pip install shap==0.45.1\n",
    "    %pip install tensorflow==2.15.1\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c609f8",
   "metadata": {
    "papermill": {
     "duration": 0.029221,
     "end_time": "2024-06-01T21:50:26.069649",
     "exception": false,
     "start_time": "2024-06-01T21:50:26.040428",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cloud Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4026e619",
   "metadata": {
    "_cell_guid": "cf2e55fb-0872-49df-ae06-aa49505f9474",
    "_uuid": "ccc8fcee-37e2-48b5-8501-6285d13e13cd",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-01T21:50:26.126258Z",
     "iopub.status.busy": "2024-06-01T21:50:26.125870Z",
     "iopub.status.idle": "2024-06-01T21:50:26.146846Z",
     "shell.execute_reply": "2024-06-01T21:50:26.145858Z"
    },
    "id": "Q4-GoceIIfT_",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "7dcb11f2-d20e-4714-e4fe-f9895dc22aac",
    "papermill": {
     "duration": 0.051278,
     "end_time": "2024-06-01T21:50:26.148883",
     "exception": false,
     "start_time": "2024-06-01T21:50:26.097605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "IN_KAGGLE = IN_COLAB = False\n",
    "try:\n",
    "    # https://www.tensorflow.org/install/pip#windows-wsl2\n",
    "    import google.colab\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "    DATA_PATH = \"/content/drive/MyDrive/EDT dataset\"\n",
    "    MODEL_PATH = \"/content/drive/MyDrive/models\"\n",
    "    IN_COLAB = True\n",
    "    print(\"Colab!\")\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "if \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ and not IN_COLAB:\n",
    "    print(\"Running in Kaggle...\")\n",
    "    for dirname, _, filenames in os.walk(\"/kaggle/input\"):\n",
    "        for filename in filenames:\n",
    "            print(os.path.join(dirname, filename))\n",
    "    MODEL_PATH = \"./models\"\n",
    "    DATA_PATH = \"/kaggle/input/intra-day-agriculture-futures-trades-2023-2024\"\n",
    "    IN_KAGGLE = True\n",
    "    print(\"Kaggle!\")\n",
    "elif not IN_COLAB:\n",
    "    IN_KAGGLE = False\n",
    "    MODEL_PATH = \"./models\"\n",
    "    DATA_PATH = \"./data/\"\n",
    "    print(\"running localhost!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45df714",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T21:50:26.200085Z",
     "iopub.status.busy": "2024-06-01T21:50:26.199265Z",
     "iopub.status.idle": "2024-06-01T21:50:33.550553Z",
     "shell.execute_reply": "2024-06-01T21:50:33.549595Z"
    },
    "papermill": {
     "duration": 7.379249,
     "end_time": "2024-06-01T21:50:33.552669",
     "exception": false,
     "start_time": "2024-06-01T21:50:26.173420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "print(f'Tensorflow version: [{tf.__version__}]')\n",
    "\n",
    "tf.get_logger().setLevel('INFO')\n",
    "\n",
    "#tf.config.set_soft_device_placement(True)\n",
    "#tf.config.experimental.enable_op_determinism()\n",
    "#tf.random.set_seed(1)\n",
    "try:\n",
    "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "\n",
    "  tf.config.experimental_connect_to_cluster(tpu)\n",
    "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "  strategy = tf.distribute.TPUStrategy(tpu)\n",
    "except Exception as e:\n",
    "  gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "  if len(gpus) > 0:\n",
    "    try:\n",
    "        strategy = tf.distribute.MirroredStrategy()\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        print(\"Running on\", len(tf.config.list_physical_devices('GPU')), \"GPU(s)\")\n",
    "  else:\n",
    "    # CPU is final fallback\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "    print(\"Running on CPU\")\n",
    "\n",
    "def is_tpu_strategy(strategy):\n",
    "    return isinstance(strategy, tf.distribute.TPUStrategy)\n",
    "\n",
    "print(\"Number of accelerators:\", strategy.num_replicas_in_sync)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a920618",
   "metadata": {
    "papermill": {
     "duration": 0.024152,
     "end_time": "2024-06-01T21:50:33.601406",
     "exception": false,
     "start_time": "2024-06-01T21:50:33.577254",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Instruments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b6fb2d",
   "metadata": {
    "papermill": {
     "duration": 0.023657,
     "end_time": "2024-06-01T21:50:33.649143",
     "exception": false,
     "start_time": "2024-06-01T21:50:33.625486",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3c109e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T21:50:33.698526Z",
     "iopub.status.busy": "2024-06-01T21:50:33.698028Z",
     "iopub.status.idle": "2024-06-01T21:50:36.189295Z",
     "shell.execute_reply": "2024-06-01T21:50:36.188362Z"
    },
    "papermill": {
     "duration": 2.519825,
     "end_time": "2024-06-01T21:50:36.192863",
     "exception": false,
     "start_time": "2024-06-01T21:50:33.673038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from algo_trading_utility_script import *\n",
    "\n",
    "filename = f\"{DATA_PATH}{os.sep}futures_{INTERVAL}.csv\"\n",
    "print(filename)\n",
    "futs_df = pd.read_csv(filename, index_col=\"Date\", parse_dates=True)\n",
    "\n",
    "print(futs_df.shape)\n",
    "\n",
    "HALF_LIFE, HURST = get_ou(futs_df, f'{TARGET_FUT}_Close')\n",
    "\n",
    "print(\"Half-Life:\", HALF_LIFE)\n",
    "print(\"Hurst:\", HURST)\n",
    "\n",
    "futs_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79e96a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T21:50:36.289999Z",
     "iopub.status.busy": "2024-06-01T21:50:36.289683Z",
     "iopub.status.idle": "2024-06-01T21:50:36.789092Z",
     "shell.execute_reply": "2024-06-01T21:50:36.788212Z"
    },
    "papermill": {
     "duration": 0.543907,
     "end_time": "2024-06-01T21:50:36.791432",
     "exception": false,
     "start_time": "2024-06-01T21:50:36.247525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.plot(futs_df[f'{TARGET_FUT}_Close'], label=f'{TARGET_FUT} Close', alpha=0.7)\n",
    "plt.title(f'{TARGET_FUT} Price')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740fd691",
   "metadata": {
    "papermill": {
     "duration": 0.025487,
     "end_time": "2024-06-01T21:50:36.842694",
     "exception": false,
     "start_time": "2024-06-01T21:50:36.817207",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e040b51b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T21:50:36.895106Z",
     "iopub.status.busy": "2024-06-01T21:50:36.894829Z",
     "iopub.status.idle": "2024-06-01T22:04:21.859254Z",
     "shell.execute_reply": "2024-06-01T22:04:21.858294Z"
    },
    "papermill": {
     "duration": 824.993229,
     "end_time": "2024-06-01T22:04:21.861471",
     "exception": false,
     "start_time": "2024-06-01T21:50:36.868242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler, normalize, FunctionTransformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "BIAS = 0.\n",
    "CLASS_WEIGHTS = {0: 1., 1: 1.}\n",
    "SCALERS = None\n",
    "TEST_SPLIT = 0.8\n",
    "TRAIN_SIZE = int(len(futs_df) * TEST_SPLIT)\n",
    "CACHE = True\n",
    "FUTURES_TMP_FILE = \"./tmp/futures.pkl\"\n",
    "os.makedirs(\"./tmp/\", exist_ok=True)\n",
    "\n",
    "# FEATURES_SELECTED from feature selection GBC notebook.\n",
    "COLS_TO_SCALE = ['10Y_Barcount', '10Y_Spread', '10Y_Volume', '2YY_Spread', '2YY_Volume',\n",
    "                'Filtered_X', 'KG_X', 'KG_Z1', 'RTY_Spread', 'SD', 'Spread',\n",
    "                'VXM_Open', 'VXM_Spread', 'Volume'] # StockFeat.list + MARKET_COLS + BB_COLS + SR_COLS + KF_COLS # FEATURES_SELECTED\n",
    "FEATURES = FEATURES_SELECTED # StockFeat.list + MARKET_COLS + KF_COLS + BB_COLS + MOM_COLS + SR_COLS # FEATURES_SELECTED\n",
    "\n",
    "print(f\"Scaling these features: {COLS_TO_SCALE}\")\n",
    "print(f\"Training on these features: {FEATURES}\")\n",
    "\n",
    "def oversample_mean_reversions(train_agri_ts, window, period=INTERVAL, hurst=HURST):\n",
    "    samples = []\n",
    "    for df in tqdm(train_agri_ts, desc=\"oversample_mean_reversions\"):\n",
    "        bb_df = df.copy()\n",
    "        results_df = param_search_bbs(bb_df, StockFeatExt.CLOSE, period, initial_window=window * 2, window_min=window // 2, hurst=hurst)\n",
    "        results_df = results_df[results_df[\"Metric\"] == \"Sharpe\"]\n",
    "        bb_df, _ = bollinger_band_backtest(bb_df, StockFeatExt.CLOSE, results_df[\"Window\"].iloc[0], period, std_factor=results_df[\"Standard_Factor\"].iloc[0])\n",
    "\n",
    "        samples.append(bb_df[train_agri_ts[0].columns].reset_index(drop=True))\n",
    "    return train_agri_ts + samples\n",
    "\n",
    "def normalize_and_label_data(ts, meta_label=META_LABEL, cols_to_scale=COLS_TO_SCALE, scalers=None):\n",
    "    def _get_first_difference(data_df):\n",
    "        return data_df.diff(1).fillna(0)\n",
    "\n",
    "    def _get_log_returns(data_df):\n",
    "        return np.log(data_df / data_df.shift(1)).fillna(0)\n",
    "\n",
    "    y0 = 0\n",
    "    y1 = 0\n",
    "    dfs = []\n",
    "    new_scalers = []\n",
    "    for df, scaler in tqdm(zip(ts, scalers or [None] * len(ts)), desc=\"label_data\"):\n",
    "        df = aug_metalabel_mr(df)\n",
    "        if (df[meta_label] > 0).sum() == 0:\n",
    "            print(\"A DS with no Positive Label was found!\")\n",
    "            continue\n",
    "        y0 += (df[meta_label] == 0).sum()\n",
    "        y1 += (df[meta_label] > 0).sum()\n",
    "        if cols_to_scale is not None:\n",
    "            if scaler is None:\n",
    "                scaler= StandardScaler() # FunctionTransformer(_get_first_difference) #\n",
    "                scaler.fit(df[cols_to_scale])\n",
    "                new_scalers.append(scaler)\n",
    "            df[cols_to_scale] = scaler.transform(df[cols_to_scale])\n",
    "            df = df.iloc[1:] # First data is always nan after a transform\n",
    "        df = df.loc[:, ~df.columns.duplicated(keep=\"first\")]\n",
    "        dfs.append(df.dropna())\n",
    "\n",
    "    # Unless we SMOTE, this dataset is imbalanced.\n",
    "    total = y0 + y1\n",
    "    class_weight_0 = total / y0 if y0 != 0 else 0\n",
    "    class_weight_1 = total / y1 if y1 != 0 else 0\n",
    "    class_weights = {0: class_weight_0, 1: class_weight_1}\n",
    "\n",
    "    # the bias will shift activation to be more sensible to the imbalance.\n",
    "    bias = np.log(y1 / y0)\n",
    "\n",
    "    return dfs, class_weights, bias, new_scalers if len(new_scalers)> 0 else scalers\n",
    "\n",
    "with strategy.scope():\n",
    "    if not os.path.exists(FUTURES_TMP_FILE):\n",
    "        futs_exog_df = process_exog(MARKET_FUTS, futs_df)\n",
    "        train_agri_ts, val_agri_ts = process_futures(FUTS, futs_df, futs_exog_df, TRAIN_SIZE, INTERVAL)\n",
    "        # Same as SMOTE, but reusing the same TS with different MR algos.\n",
    "        train_agri_ts = oversample_mean_reversions(train_agri_ts, HALF_LIFE)\n",
    "        val_agri_ts = oversample_mean_reversions(val_agri_ts, HALF_LIFE)\n",
    "        if CACHE:\n",
    "            with open(FUTURES_TMP_FILE, 'wb') as f:\n",
    "                pickle.dump((train_agri_ts, val_agri_ts), f)\n",
    "    else:\n",
    "        with open(FUTURES_TMP_FILE, 'rb') as f:\n",
    "            train_agri_ts, val_agri_ts = pickle.load(f)\n",
    "    train_agri_ts, CLASS_WEIGHTS, BIAS, SCALERS = normalize_and_label_data(train_agri_ts, cols_to_scale=COLS_TO_SCALE)\n",
    "    val_agri_ts, val_weights, _, _ = normalize_and_label_data(val_agri_ts, cols_to_scale=COLS_TO_SCALE, scalers=SCALERS)\n",
    "\n",
    "print(f\"train weights: {CLASS_WEIGHTS}\")\n",
    "print(f\"test weights: {val_weights}\")\n",
    "np.shape(train_agri_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7062b206",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T22:04:22.925775Z",
     "iopub.status.busy": "2024-06-01T22:04:22.925401Z",
     "iopub.status.idle": "2024-06-01T22:04:22.961381Z",
     "shell.execute_reply": "2024-06-01T22:04:22.960246Z"
    },
    "papermill": {
     "duration": 0.579166,
     "end_time": "2024-06-01T22:04:22.963608",
     "exception": false,
     "start_time": "2024-06-01T22:04:22.384442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = val_agri_ts[0]\n",
    "print(sample[META_LABEL].value_counts())\n",
    "\n",
    "sampled_pattenrs = sample[sample[META_LABEL] > 0]\n",
    "sampled_pattenrs[FEATURES + [META_LABEL, \"Ret\"]].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970cc401",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T22:04:24.041750Z",
     "iopub.status.busy": "2024-06-01T22:04:24.041173Z",
     "iopub.status.idle": "2024-06-01T22:04:24.116381Z",
     "shell.execute_reply": "2024-06-01T22:04:24.115529Z"
    },
    "papermill": {
     "duration": 0.589586,
     "end_time": "2024-06-01T22:04:24.118368",
     "exception": false,
     "start_time": "2024-06-01T22:04:23.528782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "WINDOW = 511  # window is the k+k-1xd-1 or the sum i=0..n of 1+sum(receptive feild)x2^i\n",
    "WINDOW_TMP_PATH = \"./tmp/\"\n",
    "# TPU see: https://github.com/tensorflow/tensorflow/issues/41635\n",
    "BATCH_SIZE = 8  * strategy.num_replicas_in_sync # Default 8\n",
    "print(f\"BATCH_SIZE: {BATCH_SIZE}\")\n",
    "\n",
    "def prepare_windows(data_df, label_df, window_size=WINDOW):\n",
    "    \"\"\"\n",
    "    Prepare windows of features and corresponding labels for classification.\n",
    "    IMPORTANT: There is no padding, incomplete timewindows are discarded!\n",
    "\n",
    "    Parameters:\n",
    "    - data_df: DataFrame containing the features.\n",
    "    - label_df: DataFrame containing the labels.\n",
    "    - window_size: The size of the input window.\n",
    "\n",
    "    Returns:\n",
    "    - X: Array of input windows.\n",
    "    - y: Array of corresponding labels.\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data_df) - window_size):\n",
    "        input_window = data_df.iloc[i : i + window_size].values\n",
    "        assert not np.isnan(input_window).any(), \"NaN values found in input window\"\n",
    "        X.append(input_window)\n",
    "        if label_df is not None:\n",
    "            target_label = label_df.iloc[i + window_size]\n",
    "            y.append([target_label])\n",
    "            assert not np.isnan(target_label).any(), \"NaN values found in target label\"\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def prepare_windows_with_disjoint_ts(ts_list, window_size=WINDOW):\n",
    "    \"\"\"\n",
    "    Generator function to yield windows of features and corresponding labels from multiple time series.\n",
    "\n",
    "    Parameters:\n",
    "    - ts_list: List of DataFrames, each containing a time series.\n",
    "    - window_size: The size of the input window.\n",
    "\n",
    "    Yields:\n",
    "    - features: The input window of features.\n",
    "    - labels: The corresponding label.\n",
    "    \"\"\"\n",
    "    for data_df in ts_list:\n",
    "        X, y = prepare_windows(data_df[FEATURES], data_df[META_LABEL], window_size=window_size)\n",
    "        for features, labels in zip(X, y):\n",
    "            yield features, labels\n",
    "\n",
    "def create_windowed_dataset_from_generator(ts_list, window_size=WINDOW, batch_size=BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    Create a TensorFlow dataset from a generator.\n",
    "\n",
    "    Parameters:\n",
    "    - ts_list: List of DataFrames, each containing a time series.\n",
    "    - window_size: The size of the input window.\n",
    "    - batch_size: The batch size for the dataset.\n",
    "\n",
    "    Returns:\n",
    "    - dataset: A TensorFlow dataset.\n",
    "    \"\"\"\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: prepare_windows_with_disjoint_ts(ts_list, window_size=window_size),\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(window_size, len(FEATURES)), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(1,), dtype=tf.float32)  # Assuming labels are floats for binary classification\n",
    "        )\n",
    "    )\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def create_dataset_from_generator(ts_list, batch_size):\n",
    "    def generator(ts_list):\n",
    "        full_df = pd.concat(ts_list)\n",
    "        for i, row in full_df.iterrows():\n",
    "            yield row[FEATURES].values, row[META_LABEL]  # Reshape to match (1,)\n",
    "\n",
    "    output_signature = (\n",
    "        tf.TensorSpec(shape=(len(FEATURES),), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(), dtype=tf.float32)\n",
    "    )\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: generator(ts_list),\n",
    "        output_signature=output_signature\n",
    "    )\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "with strategy.scope():\n",
    "    train_dataset = create_windowed_dataset_from_generator(train_agri_ts, batch_size=BATCH_SIZE)\n",
    "    val_dataset = create_windowed_dataset_from_generator(val_agri_ts, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d4b9ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T22:04:25.144082Z",
     "iopub.status.busy": "2024-06-01T22:04:25.143258Z",
     "iopub.status.idle": "2024-06-01T22:04:25.814586Z",
     "shell.execute_reply": "2024-06-01T22:04:25.813584Z"
    },
    "papermill": {
     "duration": 1.189539,
     "end_time": "2024-06-01T22:04:25.816702",
     "exception": false,
     "start_time": "2024-06-01T22:04:24.627163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# INPUT_SHAPE = (len(FEATURES), ) # The expected shape, where the None shape is BATCH_SIZE\n",
    "\n",
    "sampled_dataset = val_dataset.shuffle(buffer_size=250).take(1)\n",
    "for features, labels in train_dataset.take(1):\n",
    "    INPUT_SHAPE = features.numpy().shape[1:]  # Assuming the shape is (batch_size, len(FEATURES))\n",
    "    print(\"Features:\", features.numpy())\n",
    "    print(\"Labels:\", labels.numpy())\n",
    "\n",
    "print(\"INPUT_SHAPE:\", INPUT_SHAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dcea7e",
   "metadata": {
    "papermill": {
     "duration": 0.511757,
     "end_time": "2024-06-01T22:04:26.898618",
     "exception": false,
     "start_time": "2024-06-01T22:04:26.386861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CNN \n",
    "\n",
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4962db0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T22:04:27.946404Z",
     "iopub.status.busy": "2024-06-01T22:04:27.945702Z",
     "iopub.status.idle": "2024-06-01T22:04:27.973677Z",
     "shell.execute_reply": "2024-06-01T22:04:27.972731Z"
    },
    "papermill": {
     "duration": 0.55979,
     "end_time": "2024-06-01T22:04:27.975565",
     "exception": false,
     "start_time": "2024-06-01T22:04:27.415775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv1D, Add, Multiply, Input, Flatten, Dense, GlobalAveragePooling1D, MaxPooling1D, SpatialDropout1D, Activation, Dropout, ReLU, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2, l1, l1_l2\n",
    "from tensorflow.keras.initializers import Constant, HeNormal\n",
    "\n",
    "MODEL_NAME = None\n",
    "MAX_DILATION = 8\n",
    "FILTERS = 32\n",
    "DROPRATE = 0.4\n",
    "KERNEL_SIZE = 3\n",
    "REG_WEIGHTS = 1e-5\n",
    "CONVOLUTIONS = 12\n",
    "DENSE_SIZE = 128\n",
    "DENSE_DEPTH = 8\n",
    "\n",
    "def resnet_block(in_x, layer_id, filters, kernel_size, reg_param, stride=1):\n",
    "    # Convolutionals\n",
    "    x = Conv1D(filters, kernel_size,\n",
    "               strides=stride,\n",
    "               padding='same',\n",
    "               kernel_regularizer=l2(reg_param),\n",
    "               name=f'conv1_{layer_id}')(in_x)\n",
    "    x = BatchNormalization(name=f'bn1_{layer_id}')(x)\n",
    "    x = ReLU(name=f'relu1_{layer_id}')(x)\n",
    "    x = Conv1D(filters, kernel_size,\n",
    "               strides=1,\n",
    "               padding='same',\n",
    "               kernel_regularizer=l2(reg_param),\n",
    "               name=f'conv2_{layer_id}')(x)\n",
    "    x = BatchNormalization(name=f'bn2_{layer_id}')(x)\n",
    "\n",
    "    # Identity shortcut\n",
    "    if in_x.shape[-1] != filters or stride != 1:\n",
    "        in_x = Conv1D(filters, 1, strides=stride,\n",
    "                      padding='same',\n",
    "                      kernel_regularizer=l2(reg_param),\n",
    "                      name=f'conv_shortcut_{layer_id}')(in_x)\n",
    "        in_x = BatchNormalization(name=f'bn_shortcut_{layer_id}')(in_x)\n",
    "\n",
    "    # Residual\n",
    "    x = Add(name=f'add_{layer_id}')([x, in_x])\n",
    "    x = ReLU(name=f'relu2_{layer_id}')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def build_resnet_model(input_shape, reg_param=1e-4):\n",
    "    MODEL_NAME = \"RESNET\"\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv1D(64, 7, strides=2, padding='same', kernel_regularizer=l2(reg_param), name='initial_conv')(inputs)\n",
    "    x = BatchNormalization(name='initial_bn')(x)\n",
    "    x = ReLU(name='initial_relu')(x)\n",
    "    x = MaxPooling1D(pool_size=3, strides=2, padding='same', name='initial_maxpool')(x)\n",
    "\n",
    "    # Incremental Residual Blocks - same as the paper's 34-layer architecture\n",
    "    filters = 64\n",
    "    for i in range(3):\n",
    "        x = resnet_block(x, layer_id=f'conv2_{i}', filters=filters, kernel_size=3, reg_param=reg_param)\n",
    "    filters = 128\n",
    "    for i in range(4):\n",
    "        stride = 1 if i == 0 else 2\n",
    "        x = resnet_block(x, layer_id=f'conv3_{i}', filters=filters, stride=stride, kernel_size=3, reg_param=reg_param)\n",
    "    filters = 256\n",
    "    for i in range(6):\n",
    "        stride = 1 if i == 0 else 2\n",
    "        x = resnet_block(x, layer_id=f'conv4_{i}', filters=filters, stride=stride, kernel_size=3, reg_param=reg_param)\n",
    "    filters = 512\n",
    "    for i in range(3):\n",
    "        stride = 1 if i == 0 else 2\n",
    "        x = resnet_block(x, layer_id=f'conv5_{i}', filters=filters, stride=stride, kernel_size=3, reg_param=reg_param)\n",
    "\n",
    "    x = GlobalAveragePooling1D(name='global_avg_pool')(x)\n",
    "    outputs = Dense(1, activation='sigmoid', name='output_dense')(x)\n",
    "\n",
    "    model = Model(inputs, outputs, name=MODEL_NAME)\n",
    "    return model\n",
    "\n",
    "\n",
    "def dense_residual_block(in_x, units, reg_param, dropout_rate, layer_id):\n",
    "    x = Dense(units, kernel_regularizer=l2(reg_param), name=f'dense_{layer_id}_1')(in_x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Dense(units, kernel_regularizer=l2(reg_param), name=f'dense_{layer_id}_2')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    if in_x.shape[-1] != units:\n",
    "        # Original RESNet had a Conv1D\n",
    "        in_x = Dense(units, kernel_initializer=HeNormal(), kernel_regularizer=l1_l2(reg_param))(in_x)\n",
    "    x = Add()([in_x, x])\n",
    "    x = LeakyReLU()(x)\n",
    "    return x\n",
    "\n",
    "def build_deep_resnet_model(input_shape,\n",
    "                            reg_param=REG_WEIGHTS,\n",
    "                            dropout_rate=DROPRATE,\n",
    "                            output_bias=BIAS,\n",
    "                            dense_units = DENSE_SIZE,\n",
    "                            dense_layers = DENSE_DEPTH):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for layer_id in range(dense_layers):\n",
    "        x = dense_residual_block(x, dense_units, reg_param, dropout_rate, layer_id)\n",
    "\n",
    "    outputs = Dense(1, activation='sigmoid', name='output_dense', bias_initializer=Constant(output_bias))(x)\n",
    "    model = Model(inputs, outputs, name=MODEL_NAME)\n",
    "    return model\n",
    "\n",
    "def build_baseline_model(input_shape,\n",
    "                        reg_param=REG_WEIGHTS,\n",
    "                        dropout_rate=DROPRATE,\n",
    "                        output_bias=BIAS,\n",
    "                        dense_size = DENSE_SIZE):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = Dense(dense_size, kernel_regularizer=l1_l2(reg_param), kernel_initializer=HeNormal())(inputs)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dense(dense_size, kernel_regularizer=l1_l2(reg_param), kernel_initializer=HeNormal())(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    outputs = Dense(1, activation='sigmoid', name='output_dense', bias_initializer=Constant(output_bias))(x)\n",
    "\n",
    "    return Model(inputs, outputs, name=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5f1d4c",
   "metadata": {
    "papermill": {
     "duration": 0.510579,
     "end_time": "2024-06-01T22:04:29.044051",
     "exception": false,
     "start_time": "2024-06-01T22:04:28.533472",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9306c079",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T22:04:30.062588Z",
     "iopub.status.busy": "2024-06-01T22:04:30.061632Z",
     "iopub.status.idle": "2024-06-02T00:30:25.045595Z",
     "shell.execute_reply": "2024-06-02T00:30:25.044637Z"
    },
    "papermill": {
     "duration": 8763.009363,
     "end_time": "2024-06-02T00:30:32.562642",
     "exception": false,
     "start_time": "2024-06-01T22:04:29.553279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 117\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mINPUT_SHAPE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 117\u001b[0m     model, history \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_cnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINPUT_SHAPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m     history_dict \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory\n\u001b[1;32m    119\u001b[0m     model\u001b[38;5;241m.\u001b[39msave(MODEL_PATH)\n",
      "Cell \u001b[0;32mIn[11], line 96\u001b[0m, in \u001b[0;36mbuild_cnn\u001b[0;34m(input_shape, train_dataset, test_dataset, lr, lr_min, target_metric, patience, epochs, class_weight, initial_bias, conv_layers, max_dilation, filters, kernel_size, reg_param, dropout_rate, dense_units, dense_layers)\u001b[0m\n\u001b[1;32m     61\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     62\u001b[0m     loss\u001b[38;5;241m=\u001b[39mloss,\n\u001b[1;32m     63\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m     ],\n\u001b[1;32m     74\u001b[0m )\n\u001b[1;32m     75\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     76\u001b[0m     EarlyStopping(\n\u001b[1;32m     77\u001b[0m         patience\u001b[38;5;241m=\u001b[39mpatience,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m     )\n\u001b[1;32m     95\u001b[0m ]\n\u001b[0;32m---> 96\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, history\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:905\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    901\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[1;32m    902\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[1;32m    904\u001b[0m     \u001b[38;5;66;03m# no_variable_creation function.\u001b[39;00m\n\u001b[0;32m--> 905\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    909\u001b[0m   bound_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\n\u001b[1;32m    910\u001b[0m       \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds\n\u001b[1;32m    911\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:132\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    130\u001b[0m args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[1;32m    131\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m--> 132\u001b[0m function \u001b[38;5;241m=\u001b[39m \u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/framework/func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m   1058\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:598\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    595\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 598\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    599\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:41\u001b[0m, in \u001b[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m     51\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filea2usmwj9.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    330\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: from cache\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n\u001b[0;32m--> 331\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m ag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED:\n\u001b[1;32m    334\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: AutoGraph is disabled in context\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:460\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/keras/src/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1380\u001b[0m     run_step \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfunction(\n\u001b[1;32m   1381\u001b[0m         run_step, jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reduce_retracing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1382\u001b[0m     )\n\u001b[1;32m   1383\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[0;32m-> 1384\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[1;32m   1386\u001b[0m     outputs,\n\u001b[1;32m   1387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[1;32m   1388\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_reduction_method,\n\u001b[1;32m   1389\u001b[0m )\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:1681\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1676\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m   1677\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1678\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1679\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   1680\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1681\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:3271\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3269\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   3270\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 3271\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/distribute/mirrored_strategy.py:700\u001b[0m, in \u001b[0;36mMirroredExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m--> 700\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmirrored_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_container_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/distribute/mirrored_run.py:102\u001b[0m, in \u001b[0;36mcall_for_each_replica\u001b[0;34m(strategy, fn, args, kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m   \u001b[38;5;66;03m# When a tf.function is wrapped to trigger _call_for_each_replica (see\u001b[39;00m\n\u001b[1;32m     96\u001b[0m   \u001b[38;5;66;03m# the other branch above), AutoGraph stops conversion at\u001b[39;00m\n\u001b[1;32m     97\u001b[0m   \u001b[38;5;66;03m# _call_for_each_replica itself (TF library functions are allowlisted).\u001b[39;00m\n\u001b[1;32m     98\u001b[0m   \u001b[38;5;66;03m# This makes sure that the Python function that originally passed to\u001b[39;00m\n\u001b[1;32m     99\u001b[0m   \u001b[38;5;66;03m# the tf.function is still converted.\u001b[39;00m\n\u001b[1;32m    100\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx())\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/distribute/mirrored_run.py:284\u001b[0m, in \u001b[0;36m_call_for_each_replica\u001b[0;34m(distribution, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m threads:\n\u001b[1;32m    283\u001b[0m     t\u001b[38;5;241m.\u001b[39mshould_run\u001b[38;5;241m.\u001b[39mset()\n\u001b[0;32m--> 284\u001b[0m   \u001b[43mcoord\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthreads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m distribute_utils\u001b[38;5;241m.\u001b[39mregroup(\u001b[38;5;28mtuple\u001b[39m(t\u001b[38;5;241m.\u001b[39mmain_result \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m threads))\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/training/coordinator.py:386\u001b[0m, in \u001b[0;36mCoordinator.join\u001b[0;34m(self, threads, stop_grace_period_secs, ignore_live_threads)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info_to_raise:\n\u001b[1;32m    385\u001b[0m   _, ex_instance, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info_to_raise\n\u001b[0;32m--> 386\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ex_instance\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m stragglers:\n\u001b[1;32m    388\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m ignore_live_threads:\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/training/coordinator.py:293\u001b[0m, in \u001b[0;36mCoordinator.stop_on_exception\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Context manager to request stop when an Exception is raised.\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03mCode that uses a coordinator must catch exceptions and pass\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03m  nothing.\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 293\u001b[0m   \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=bare-except\u001b[39;00m\n\u001b[1;32m    295\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_stop(ex\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mexc_info())\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/distribute/mirrored_run.py:277\u001b[0m, in \u001b[0;36m_call_for_each_replica\u001b[0;34m(distribution, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m# Control is transfered from _MirroredReplicaThread (MRT) to the main\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# thread, i.e., here, to perform `merge_fn`, and thus we preserve the\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# name scope,  control dependencies, etc. from MRT at the time\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m# mode scope as well so that `merge_fn` does not have trouble\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;66;03m# accessing resources defined in MRT under the same context.\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(\n\u001b[1;32m    273\u001b[0m     mtt_captured_name_scope), ops\u001b[38;5;241m.\u001b[39mcontrol_dependencies(\n\u001b[1;32m    274\u001b[0m         mtt_captured_control_deps), variable_scope\u001b[38;5;241m.\u001b[39mvariable_scope(\n\u001b[1;32m    275\u001b[0m             mtt_captured_var_scope), _maybe_enter_eager_mode(\n\u001b[1;32m    276\u001b[0m                 threads[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmerge_call_entered_in_eager):\n\u001b[0;32m--> 277\u001b[0m   merge_result \u001b[38;5;241m=\u001b[39m \u001b[43mthreads\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistribution\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmerge_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m                                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmerge_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(threads):\n\u001b[1;32m    280\u001b[0m   t\u001b[38;5;241m.\u001b[39mmerge_result \u001b[38;5;241m=\u001b[39m distribute_utils\u001b[38;5;241m.\u001b[39mselect_replica(r, merge_result)\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    330\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: from cache\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n\u001b[0;32m--> 331\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m ag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED:\n\u001b[1;32m    334\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: AutoGraph is disabled in context\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/keras/src/optimizers/optimizer.py:1345\u001b[0m, in \u001b[0;36mOptimizer._distributed_apply_gradients_fn\u001b[0;34m(self, distribution, grads_and_vars, **kwargs)\u001b[0m\n\u001b[1;32m   1342\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_step(grad, var)\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m grad, var \u001b[38;5;129;01min\u001b[39;00m grads_and_vars:\n\u001b[0;32m-> 1345\u001b[0m     \u001b[43mdistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_grad_to_update_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   1347\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_ema:\n\u001b[1;32m   1350\u001b[0m     _, var_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mgrads_and_vars)\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:3013\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3010\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   3011\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3012\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 3013\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3014\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3015\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_replica_ctx_update(\n\u001b[1;32m   3016\u001b[0m       var, fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs, group\u001b[38;5;241m=\u001b[39mgroup)\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/distribute/mirrored_strategy.py:815\u001b[0m, in \u001b[0;36mMirroredExtended._update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m    809\u001b[0m   name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdate_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m i\n\u001b[1;32m    810\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mdevice(v\u001b[38;5;241m.\u001b[39mdevice), \\\n\u001b[1;32m    811\u001b[0m        distribute_lib\u001b[38;5;241m.\u001b[39mUpdateContext(i), \\\n\u001b[1;32m    812\u001b[0m        ops\u001b[38;5;241m.\u001b[39mname_scope(name):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;66;03m# If args and kwargs are not mirrored, the value is returned as is.\u001b[39;00m\n\u001b[1;32m    814\u001b[0m     updates\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 815\u001b[0m         \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdistribute_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m           \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdistribute_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m distribute_utils\u001b[38;5;241m.\u001b[39mupdate_regroup(\u001b[38;5;28mself\u001b[39m, updates, group)\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    330\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: from cache\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n\u001b[0;32m--> 331\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m ag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED:\n\u001b[1;32m    334\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: AutoGraph is disabled in context\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/keras/src/optimizers/optimizer.py:1340\u001b[0m, in \u001b[0;36mOptimizer._distributed_apply_gradients_fn.<locals>.apply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m   1338\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_grad_to_update_var\u001b[39m(var, grad):\n\u001b[1;32m   1339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit_compile:\n\u001b[0;32m-> 1340\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_step_xla\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_var_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1341\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1342\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_step(grad, var)\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:877\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 877\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    881\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    882\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:132\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    130\u001b[0m args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[1;32m    131\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m--> 132\u001b[0m function \u001b[38;5;241m=\u001b[39m \u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:239\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    229\u001b[0m lookup_func_type, lookup_func_context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    230\u001b[0m     function_type_utils\u001b[38;5;241m.\u001b[39mmake_canonicalized_monomorphic_type(\n\u001b[1;32m    231\u001b[0m         args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m     )\n\u001b[1;32m    236\u001b[0m )\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 239\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlookup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m      \u001b[49m\u001b[43mlookup_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_func_context\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/core/function/polymorphism/function_cache.py:48\u001b[0m, in \u001b[0;36mFunctionCache.lookup\u001b[0;34m(self, function_type, context)\u001b[0m\n\u001b[1;32m     46\u001b[0m context \u001b[38;5;241m=\u001b[39m context \u001b[38;5;129;01mor\u001b[39;00m FunctionContext()\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_dict:\n\u001b[0;32m---> 48\u001b[0m   dispatch_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dispatch_type:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_primary[(context, dispatch_type)]\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/core/function/polymorphism/type_dispatch.py:93\u001b[0m, in \u001b[0;36mTypeDispatchTable.dispatch\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     91\u001b[0m most_specific_supertype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m other \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_table:\n\u001b[0;32m---> 93\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_supertype_of\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m most_specific_supertype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m other\u001b[38;5;241m.\u001b[39mis_supertype_of(\n\u001b[1;32m     95\u001b[0m         most_specific_supertype):\n\u001b[1;32m     96\u001b[0m       most_specific_supertype \u001b[38;5;241m=\u001b[39m other\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/core/function/polymorphism/function_type.py:292\u001b[0m, in \u001b[0;36mFunctionType.is_supertype_of\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    287\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m self_param, other_param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    290\u001b[0m                                    other\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    291\u001b[0m   \u001b[38;5;66;03m# Functions are contravariant on their parameter types.\u001b[39;00m\n\u001b[0;32m--> 292\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mself_param\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_subtype_of\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother_param\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# Other must have all capture names of self.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/core/function/polymorphism/function_type.py:123\u001b[0m, in \u001b[0;36mParameter.is_subtype_of\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkind, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptional) \u001b[38;5;241m!=\u001b[39m\n\u001b[1;32m    120\u001b[0m     (other\u001b[38;5;241m.\u001b[39mname, other\u001b[38;5;241m.\u001b[39mkind, other\u001b[38;5;241m.\u001b[39moptional)):\n\u001b[1;32m    121\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_constraint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_subtype_of\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_constraint\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/ops/resource_variable_ops.py:2692\u001b[0m, in \u001b[0;36mVariableSpec.is_subtype_of\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   2687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malias_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m other\u001b[38;5;241m.\u001b[39malias_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2688\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVariableSpec.is_subtype_of doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt support \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2689\u001b[0m                             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malias_id=None, got self: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and other: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2690\u001b[0m                             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mother\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2692\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_subtype_of\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/framework/type_spec.py:143\u001b[0m, in \u001b[0;36mTypeSpec.is_subtype_of\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    139\u001b[0m       is_subtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    142\u001b[0m   \u001b[38;5;66;03m# TODO(b/217959193): Replace _serialize with parameter decomposition.\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m   \u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_attribute\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    145\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/util/nest.py:631\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnest.map_structure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_structure\u001b[39m(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    547\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \n\u001b[1;32m    549\u001b[0m \u001b[38;5;124;03m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03m    ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModality\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCORE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:1066\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    970\u001b[0m \n\u001b[1;32m    971\u001b[0m \u001b[38;5;124;03m- For Modality.CORE: Refer to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;124;03m  ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mCORE:\n\u001b[0;32m-> 1066\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tf_core_map_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mDATA:\n\u001b[1;32m   1068\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _tf_data_map_structure(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:1104\u001b[0m, in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1101\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1102\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m-> 1104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tf_core_pack_sequence_as\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mentries\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpand_composites\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand_composites\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:904\u001b[0m, in \u001b[0;36m_tf_core_pack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites, sequence_fn)\u001b[0m\n\u001b[1;32m    901\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m flat_sequence[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 904\u001b[0m   final_index, packed \u001b[38;5;241m=\u001b[39m \u001b[43m_tf_core_packed_nest_with_indices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_nested_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequence_fn\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    907\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m final_index \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(flat_sequence):\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:572\u001b[0m, in \u001b[0;36m_tf_core_packed_nest_with_indices\u001b[0;34m(structure, flat, index, is_nested_fn, sequence_fn)\u001b[0m\n\u001b[1;32m    570\u001b[0m packed \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    571\u001b[0m sequence_fn \u001b[38;5;241m=\u001b[39m sequence_fn \u001b[38;5;129;01mor\u001b[39;00m sequence_like\n\u001b[0;32m--> 572\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_tf_core_yield_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_nested_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_tf_core_packed_nest_with_indices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m        \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_nested_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequence_fn\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:312\u001b[0m, in \u001b[0;36m_tf_core_yield_value\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_tf_core_yield_value\u001b[39m(iterable):\n\u001b[0;32m--> 312\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_tf_core_yield_sorted_items\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:347\u001b[0m, in \u001b[0;36m_tf_core_yield_sorted_items\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(iterable) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mtuple\u001b[39m:  \u001b[38;5;66;03m# pylint: disable=unidiomatic-typecheck\u001b[39;00m\n\u001b[1;32m    346\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(iterable):\n\u001b[0;32m--> 347\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m item\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(iterable, (\u001b[38;5;28mdict\u001b[39m, _collections_abc\u001b[38;5;241m.\u001b[39mMapping)):\n\u001b[1;32m    349\u001b[0m   \u001b[38;5;66;03m# Iterate through dictionaries in a deterministic order by sorting the\u001b[39;00m\n\u001b[1;32m    350\u001b[0m   \u001b[38;5;66;03m# keys. Notice this means that we ignore the original order of `OrderedDict`\u001b[39;00m\n\u001b[1;32m    351\u001b[0m   \u001b[38;5;66;03m# instances. This is intentional, to avoid potential bugs caused by mixing\u001b[39;00m\n\u001b[1;32m    352\u001b[0m   \u001b[38;5;66;03m# ordered and plain dicts (e.g., flattening a dict but using a\u001b[39;00m\n\u001b[1;32m    353\u001b[0m   \u001b[38;5;66;03m# corresponding `OrderedDict` to pack it back).\u001b[39;00m\n\u001b[1;32m    354\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m _tf_core_sorted(iterable):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, BinaryFocalCrossentropy\n",
    "from tensorflow.keras.metrics import  AUC, Precision, Recall, TruePositives, TrueNegatives, FalsePositives, FalseNegatives\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "MODEL_DIR = f\"models/{MODEL_NAME}.keras\"\n",
    "MODEL_HISTORY = f\"{MODEL_PATH}/history.json\"\n",
    "IMAGES_DIR = f\"images/{MODEL_NAME}/images\"\n",
    "LOG_BASEPATH = f\"logs/{MODEL_NAME}/tb\"\n",
    "TARGET_METRIC = \"tp\"\n",
    "\n",
    "EPOCHS = 30\n",
    "PATIENCE_EPOCHS = 5\n",
    "LEARN_RATE =1e-3\n",
    "LEARN_RATE_MIN = 1e-5\n",
    "ALPHA = CLASS_WEIGHTS[1] / (CLASS_WEIGHTS[0] + CLASS_WEIGHTS[1])\n",
    "GAMMA = 2.\n",
    "\n",
    "PURGE = True\n",
    "if PURGE:\n",
    "    # Remove tensorboard logs and other training artefacts for a fresh loop.\n",
    "    shutil.rmtree(LOG_BASEPATH, ignore_errors=True)\n",
    "    shutil.rmtree(MODEL_DIR, ignore_errors=True)\n",
    "    shutil.rmtree(IMAGES_DIR, ignore_errors=True)\n",
    "os.makedirs(IMAGES_DIR, exist_ok=True)\n",
    "os.makedirs(LOG_BASEPATH, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "print(f\"alpha: {ALPHA}, gamma {GAMMA}, bias: {BIAS}\")\n",
    "\n",
    "def build_cnn(input_shape, train_dataset, test_dataset=None,\n",
    "                lr=LEARN_RATE,\n",
    "                lr_min=LEARN_RATE_MIN,\n",
    "                target_metric=TARGET_METRIC,\n",
    "                patience=PATIENCE_EPOCHS,\n",
    "                epochs=EPOCHS,\n",
    "                class_weight=CLASS_WEIGHTS,\n",
    "                initial_bias = BIAS,\n",
    "                conv_layers = CONVOLUTIONS,\n",
    "                max_dilation = MAX_DILATION,\n",
    "                filters = FILTERS,\n",
    "                kernel_size = KERNEL_SIZE,\n",
    "                reg_param = REG_WEIGHTS,\n",
    "                dropout_rate = DROPRATE,\n",
    "                dense_units = DENSE_SIZE,\n",
    "                dense_layers = DENSE_DEPTH // 4):\n",
    "    model = build_resnet_model(\n",
    "        input_shape=input_shape,\n",
    "        reg_param=reg_param\n",
    "    )\n",
    "    optimizer = Adam(learning_rate=lr, clipnorm=1.)\n",
    "    loss = BinaryFocalCrossentropy (from_logits=False,\n",
    "                                    alpha=ALPHA,\n",
    "                                    gamma=GAMMA,\n",
    "                                    reduction='sum_over_batch_size',\n",
    "                                    name='bfce')\n",
    "    model.compile(\n",
    "        loss=loss,\n",
    "        optimizer=optimizer,\n",
    "        metrics=[\n",
    "            TruePositives(name=TARGET_METRIC), # Max TP\n",
    "            TrueNegatives(name='tn'),\n",
    "            FalsePositives(name='fp'),\n",
    "            FalseNegatives(name='fn'),\n",
    "            Precision(name='p'),\n",
    "            Recall(name='r'),\n",
    "            AUC(name='auc'),\n",
    "            AUC(name='prc', curve='PR')\n",
    "        ],\n",
    "    )\n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            patience=patience,\n",
    "            monitor=f\"val_{target_metric}\",\n",
    "            restore_best_weights=True,\n",
    "            mode=\"max\" # TARGET_METRIC max or min\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor=f\"val_{target_metric}\",\n",
    "            factor=0.5,\n",
    "            patience=1,\n",
    "            verbose=1,\n",
    "            min_lr=lr_min,\n",
    "            mode=\"max\" # TARGET_METRIC max or min\n",
    "        ),\n",
    "        TensorBoard(\n",
    "            log_dir=LOG_BASEPATH,\n",
    "            histogram_freq=1,\n",
    "            write_images=True\n",
    "        )\n",
    "    ]\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=test_dataset,\n",
    "        epochs=epochs,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1,\n",
    "        class_weight=class_weight\n",
    "    )\n",
    "    return model, history\n",
    "\n",
    "history_dict = None\n",
    "with strategy.scope():\n",
    "    if not PURGE and os.path.exists(MODEL_PATH):\n",
    "        print(f\"Loading model from: {MODEL_PATH}\")\n",
    "        model = tf.keras.models.load_model(MODEL_PATH)\n",
    "        if os.path.exists(MODEL_HISTORY):\n",
    "            with open(MODEL_HISTORY, 'r') as f:\n",
    "                history_dict = json.load(f)\n",
    "    else:\n",
    "        print(f\"input_shape: {INPUT_SHAPE}\")\n",
    "        model, history = build_cnn(INPUT_SHAPE, train_dataset=train_dataset, test_dataset=val_dataset)\n",
    "        history_dict = history.history\n",
    "        model.save(MODEL_PATH)\n",
    "        # float32 is not directly serializable to JSON\n",
    "        history_dict = {k: [float(i) for i in v] for k, v in history_dict.items()}\n",
    "        with open(MODEL_HISTORY, 'w') as f:\n",
    "            json.dump(history_dict, f)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6df88f",
   "metadata": {
    "papermill": {
     "duration": 7.435075,
     "end_time": "2024-06-02T00:30:47.607073",
     "exception": false,
     "start_time": "2024-06-02T00:30:40.171998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Visualize History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ce7dcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T00:31:02.264715Z",
     "iopub.status.busy": "2024-06-02T00:31:02.263996Z",
     "iopub.status.idle": "2024-06-02T00:31:04.396276Z",
     "shell.execute_reply": "2024-06-02T00:31:04.395313Z"
    },
    "papermill": {
     "duration": 9.523718,
     "end_time": "2024-06-02T00:31:04.399000",
     "exception": false,
     "start_time": "2024-06-02T00:30:54.875282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_model_stats(history_dict):\n",
    "    plt.figure(figsize=(18, 10))\n",
    "\n",
    "    # Plotting Loss\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.plot(history_dict['loss'], label='Train Loss')\n",
    "    plt.plot(history_dict['val_loss'], label='Val Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    # Plotting AUC\n",
    "    plt.subplot(2, 3, 2)\n",
    "    plt.plot(history_dict['auc'], label='Train AUC')\n",
    "    plt.plot(history_dict['val_auc'], label='Val AUC')\n",
    "    plt.title('Model AUC')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('AUC')\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "    # Plotting Precision\n",
    "    plt.subplot(2, 3, 3)\n",
    "    plt.plot(history_dict['p'], label='Train Precision')\n",
    "    plt.plot(history_dict['val_p'], label='Val Precision')\n",
    "    plt.title('Model Precision')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "    # Plotting Recall\n",
    "    plt.subplot(2, 3, 4)\n",
    "    plt.plot(history_dict['r'], label='Train Recall')\n",
    "    plt.plot(history_dict['val_r'], label='Val Recall')\n",
    "    plt.title('Model Recall')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "    # Plotting True Positives\n",
    "    plt.subplot(2, 3, 5)\n",
    "    plt.plot(history_dict['tp'], label='Train True Positives')\n",
    "    plt.plot(history_dict['val_tp'], label='Val True Positives')\n",
    "    plt.title('Model True Positives')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('True Positives')\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    # Plotting PRC (Precision-Recall Curve)\n",
    "    plt.subplot(2, 3, 6)\n",
    "    plt.plot(history_dict['prc'], label='Train PRC')\n",
    "    plt.plot(history_dict['val_prc'], label='Val PRC')\n",
    "    plt.title('Model PRC')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('PRC')\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{IMAGES_DIR}/{MODEL_NAME}_stats.png')\n",
    "    plt.show()\n",
    "\n",
    "if history_dict is not None:\n",
    "    plot_model_stats(history_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ab5925",
   "metadata": {
    "papermill": {
     "duration": 7.467683,
     "end_time": "2024-06-02T00:31:19.338034",
     "exception": false,
     "start_time": "2024-06-02T00:31:11.870351",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Explain and Interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315ca10c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T00:31:34.082220Z",
     "iopub.status.busy": "2024-06-02T00:31:34.081492Z",
     "iopub.status.idle": "2024-06-02T00:31:38.126155Z",
     "shell.execute_reply": "2024-06-02T00:31:38.125267Z"
    },
    "papermill": {
     "duration": 11.290591,
     "end_time": "2024-06-02T00:31:38.128051",
     "exception": false,
     "start_time": "2024-06-02T00:31:26.837460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, fbeta_score, roc_auc_score\n",
    "\n",
    "def print_metrics_and_distribution(model, data, labels):\n",
    "    ypred_proba = model.predict(data)\n",
    "    pred = (ypred_proba > 0.5).astype(int)\n",
    "\n",
    "    metrics = {\n",
    "        \"Accuracy\": accuracy_score(labels, pred.flatten()),\n",
    "        \"Precision\": precision_score(labels, pred.flatten()),\n",
    "        \"Recall\": recall_score(labels, pred.flatten()),\n",
    "        \"F1b Score\": fbeta_score(labels, pred.flatten(), average=\"weighted\", beta=0.1),\n",
    "        \"ROC AUC\": roc_auc_score(labels, ypred_proba.flatten(), average='weighted')\n",
    "    }\n",
    "\n",
    "    metrics_df = pd.DataFrame.from_dict(metrics, orient='index')\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.kdeplot(ypred_proba, color='blue', fill=True, alpha=0.7)\n",
    "\n",
    "    mu, std = norm.fit(ypred_proba)\n",
    "    xmin, xmax = plt.xlim()\n",
    "    x = np.linspace(xmin, xmax, 100)\n",
    "    p = norm.pdf(x, mu, std)\n",
    "    plt.plot(x, p, 'k', linewidth=2)\n",
    "\n",
    "    plt.title('PDF')\n",
    "    plt.xlabel('Predicted Probability')\n",
    "    plt.ylabel('Density')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{IMAGES_DIR}/{MODEL_NAME}_pdf.png')\n",
    "    plt.show()\n",
    "\n",
    "    metrics_df.to_json(f\"{MODEL_PATH}/stats.json\")\n",
    "\n",
    "    return metrics_df\n",
    "\n",
    "if MODEL_NAME == \"WAVENET\":\n",
    "    test_data, test_labels = prepare_windows(val_agri_ts[0][FEATURES], val_agri_ts[0][META_LABEL], window_size=WINDOW)\n",
    "else:\n",
    "    test_data, test_labels = val_agri_ts[0][FEATURES], val_agri_ts[0][META_LABEL]\n",
    "metrics_df = print_metrics_and_distribution(model, test_data, test_labels)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ee7e8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T00:31:52.987402Z",
     "iopub.status.busy": "2024-06-02T00:31:52.986692Z",
     "iopub.status.idle": "2024-06-02T00:31:54.272020Z",
     "shell.execute_reply": "2024-06-02T00:31:54.271143Z"
    },
    "papermill": {
     "duration": 8.697888,
     "end_time": "2024-06-02T00:31:54.274132",
     "exception": false,
     "start_time": "2024-06-02T00:31:45.576244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.math import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(model, data, labels, label_names=['RW', 'MR']):\n",
    "    ypred_proba = model.predict(data)\n",
    "    pred = (ypred_proba > 0.5).astype(int)\n",
    "\n",
    "    print(labels.shape)\n",
    "    print(pred.shape)\n",
    "    if len(labels.shape) > 0:\n",
    "        labels = labels.flatten()\n",
    "    if len(pred.shape) > 0:\n",
    "        pred = pred.flatten()\n",
    "    cm = confusion_matrix(labels, pred)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    df_cm = pd.DataFrame((cm / np.sum(cm, axis=1)[:, None])*100, index=[i for i in label_names], columns=[i for i in label_names])\n",
    "    cm_plot = sns.heatmap(df_cm, annot=True, fmt=\".2f\", cmap='Blues', xticklabels=label_names, yticklabels=label_names)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{IMAGES_DIR}/{MODEL_NAME}_cm.png')\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bd0554",
   "metadata": {
    "papermill": {
     "duration": 7.367246,
     "end_time": "2024-06-02T00:32:08.911228",
     "exception": false,
     "start_time": "2024-06-02T00:32:01.543982",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323cb9fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T00:32:23.796675Z",
     "iopub.status.busy": "2024-06-02T00:32:23.796300Z",
     "iopub.status.idle": "2024-06-02T00:32:24.752932Z",
     "shell.execute_reply": "2024-06-02T00:32:24.752097Z"
    },
    "papermill": {
     "duration": 8.366573,
     "end_time": "2024-06-02T00:32:24.759404",
     "exception": false,
     "start_time": "2024-06-02T00:32:16.392831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "RANDOMIZE_SIZE = 32\n",
    "SAMPLE_SIZE = 25\n",
    "\n",
    "if MODEL_NAME != \"WAVENET\":\n",
    "    # Shap doesn't work with window encoded data.\n",
    "    background_features, background_labels = train_agri_ts[0][FEATURES].values,train_agri_ts[0][META_LABEL].values\n",
    "    test_data, test_labels = val_agri_ts[0][FEATURES].values, val_agri_ts[0][META_LABEL].values\n",
    "    test_features, test_labels = test_data[:SAMPLE_SIZE], test_labels[:SAMPLE_SIZE]\n",
    "\n",
    "    shap.explainers._deep.deep_tf.op_handlers[\"LeakyRelu\"] = shap.explainers._deep.deep_tf.op_handlers[\"Relu\"]\n",
    "    shap.explainers._deep.deep_tf.op_handlers[\"AddV2\"] = shap.explainers._deep.deep_tf.op_handlers[\"Add\"]\n",
    "    shap.explainers._deep.deep_tf.op_handlers[\"BatchToSpaceND\"] = shap.explainers._deep.deep_tf.op_handlers[\"Mean\"]\n",
    "    shap.explainers._deep.deep_tf.op_handlers[\"SpaceToBatchND\"] = shap.explainers._deep.deep_tf.op_handlers[\"Mean\"]\n",
    "    # this is a hack: https://github.com/shap/shap/issues/1463\n",
    "\n",
    "    e = shap.DeepExplainer(model, background_features)\n",
    "\n",
    "    shap_values = e.shap_values(test_features)\n",
    "    if isinstance(shap_values, list):\n",
    "        shap_values = shap_values[0]\n",
    "    shap_values = np.squeeze(shap_values)\n",
    "\n",
    "    print(f\"SHAP values shape: {shap_values.shape}\")\n",
    "    print(f\"Test features shape: {test_features.shape}\")\n",
    "    assert shap_values.shape == test_features.shape\n",
    "    shap.summary_plot(shap_values, test_features, feature_names=FEATURES)\n",
    "    plt.savefig(f'{IMAGES_DIR}/{MODEL_NAME}_shap_sum.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8984547b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T00:32:39.601019Z",
     "iopub.status.busy": "2024-06-02T00:32:39.600326Z",
     "iopub.status.idle": "2024-06-02T00:32:39.608162Z",
     "shell.execute_reply": "2024-06-02T00:32:39.607215Z"
    },
    "papermill": {
     "duration": 7.42798,
     "end_time": "2024-06-02T00:32:39.610074",
     "exception": false,
     "start_time": "2024-06-02T00:32:32.182094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if MODEL_NAME != \"WAVENET\":\n",
    "    sample_index = 2\n",
    "    e = shap.KernelExplainer(model, background)\n",
    "\n",
    "    select = range(SAMPLE_SIZE)\n",
    "    shap_features = test_features[select]\n",
    "    train_features = background_features[select]\n",
    "    shap_values = e.shap_values(shap_features, nsamples=SAMPLE_SIZE)\n",
    "    print(f\"SHAP values shape: {shap_values.shape}\")\n",
    "\n",
    "    if isinstance(shap_values, list):\n",
    "        shap_values = shap_values[0: SAMPLE_SIZE]\n",
    "    shap_values = np.squeeze(shap_values)\n",
    "    y_pred = (shap_values.sum(1) + e.expected_value) > 0\n",
    "    misclassified = y_pred != test_labels[select]\n",
    "    print(f\"({shap_values.sum(1)} + {e.expected_value}) > 0\")\n",
    "    print(f\"Misclassified: {np.shape(misclassified)} out of {np.shape(y_pred)[0]}\")\n",
    "\n",
    "    print(f\"Explainer expected value: {e.expected_value}\")\n",
    "    shap.decision_plot(e.expected_value, shap_values, train_features, feature_names=FEATURES, link='logit', highlight=misclassified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfdb577",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T00:32:54.374960Z",
     "iopub.status.busy": "2024-06-02T00:32:54.373988Z",
     "iopub.status.idle": "2024-06-02T00:32:54.380207Z",
     "shell.execute_reply": "2024-06-02T00:32:54.379435Z"
    },
    "papermill": {
     "duration": 7.401307,
     "end_time": "2024-06-02T00:32:54.382132",
     "exception": false,
     "start_time": "2024-06-02T00:32:46.980825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if MODEL_NAME != \"WAVENET\":\n",
    "    shap.decision_plot(\n",
    "        e.expected_value,\n",
    "        shap_values[misclassified],\n",
    "        train_features[misclassified],\n",
    "        link=\"logit\",\n",
    "        highlight=0,\n",
    "        feature_names=FEATURES\n",
    "    )\n",
    "    plt.savefig(f'{IMAGES_DIR}/{MODEL_NAME}_shap_force.png')\n",
    "\n",
    "    shap.force_plot(\n",
    "        e.expected_value,\n",
    "        shap_values[misclassified],\n",
    "        train_features[misclassified],\n",
    "        link=\"logit\",\n",
    "        feature_names=FEATURES\n",
    "    )\n",
    "    plt.savefig(f'{IMAGES_DIR}/{MODEL_NAME}_shap_force_misclassed.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153c475c",
   "metadata": {
    "papermill": {
     "duration": 7.256572,
     "end_time": "2024-06-02T00:33:09.018840",
     "exception": false,
     "start_time": "2024-06-02T00:33:01.762268",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Grid Search and CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7380a1d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T00:33:23.904114Z",
     "iopub.status.busy": "2024-06-02T00:33:23.903748Z",
     "iopub.status.idle": "2024-06-02T00:33:23.948357Z",
     "shell.execute_reply": "2024-06-02T00:33:23.947645Z"
    },
    "papermill": {
     "duration": 7.457575,
     "end_time": "2024-06-02T00:33:23.950392",
     "exception": false,
     "start_time": "2024-06-02T00:33:16.492817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid, TimeSeriesSplit\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from tensorflow.summary import create_file_writer\n",
    "\n",
    "import json\n",
    "\n",
    "HP_KERNEL_SIZE = hp.HParam(\"kernel_size\", hp.Discrete([int(KERNEL_SIZE * 2), int(KERNEL_SIZE), int(KERNEL_SIZE // 2)]))\n",
    "HP_BATCH_SIZE = hp.HParam(\"batch_size\", hp.Discrete([int(BATCH_SIZE)]))\n",
    "HP_EPOCHS = hp.HParam(\"epochs\", hp.Discrete([int(EPOCHS)]))\n",
    "HP_DILATION_RATE = hp.HParam(\"dilation_rate\", hp.Discrete([int(MAX_DILATION), int(MAX_DILATION * 2)]))\n",
    "HP_DROPOUT_RATE = hp.HParam(\"dropout_rate\", hp.Discrete([float(DROPRATE), float(DROPRATE * 2)]))\n",
    "HP_REG_WEIGHTS = hp.HParam(\"reg_weight\", hp.Discrete([float(REG_WEIGHTS), float(REG_WEIGHTS / 2)]))\n",
    "HP_LEARNING_RATE = hp.HParam(\"learning_rate\", hp.Discrete([float(LEARN_RATE)]))\n",
    "HP_PATIENCE = hp.HParam(\"patience\", hp.Discrete([int(PATIENCE_EPOCHS)]))\n",
    "HP_DENSE_DEPTH = hp.HParam(\"dense_depth\", hp.Discrete([int(DENSE_DEPTH), int(DENSE_DEPTH * 2)]))\n",
    "HP_DENSE_UNITS = hp.HParam(\"dense_units\", hp.Discrete([int(DENSE_DEPTH // 2), int(DENSE_DEPTH), int(DENSE_DEPTH * 2)]))\n",
    "HP_FILTERS = hp.HParam(\"filters\", hp.Discrete([int(FILTERS // 2), int(FILTERS), int(FILTERS * 2)]))\n",
    "HP_CONVOLUTIONS= hp.HParam(\"convolutions\", hp.Discrete([int(CONVOLUTIONS // 2), int(CONVOLUTIONS), int(CONVOLUTIONS * 2)]))\n",
    "HPARAMS = [\n",
    "    HP_FILTERS,\n",
    "    HP_KERNEL_SIZE,\n",
    "    HP_BATCH_SIZE,\n",
    "    HP_EPOCHS,\n",
    "    HP_DILATION_RATE,\n",
    "    HP_DROPOUT_RATE,\n",
    "    HP_REG_WEIGHTS,\n",
    "    HP_LEARNING_RATE,\n",
    "    HP_PATIENCE,\n",
    "    HP_DENSE_UNITS,\n",
    "    HP_DENSE_DEPTH,\n",
    "    HP_CONVOLUTIONS]\n",
    "\n",
    "def grid_search_build_cnn(input_shape, train_dataset, test_dataset, hparams=HPARAMS, file_name=f\"best_params.json\", checkpoint_file = f\"checkpoint.json\"):\n",
    "    def _decode_arrays(config_str):\n",
    "        return [int(unit) for unit in config_str.split('_')]\n",
    "\n",
    "    def _save_best_params(best_params, best_loss, best_metric, other_metrics = None, file_name=\"best_params.json\"):\n",
    "        os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "        with open(f\"{MODEL_DIR}/{file_name}\", \"w\") as file:\n",
    "            json.dump({\"best_params\": best_params, \"best_loss\": best_loss, \"best_metric\": best_metric, 'other_metrics': other_metrics}, file)\n",
    "\n",
    "    def _load_checkpoint(file_name):\n",
    "        json = None\n",
    "        try:\n",
    "            os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "            with open(f\"{MODEL_DIR}/{file_name}\", \"r\") as file:\n",
    "                json = json.load(file)\n",
    "        except Exception as e:\n",
    "            print(f\"File {MODEL_DIR}/{file_name} not found or error {e}\")\n",
    "        return json\n",
    "\n",
    "    def _save_checkpoint(state, file_name):\n",
    "        os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "        with open(f\"{MODEL_DIR}/{file_name}\", \"w\") as file:\n",
    "            json.dump(state, file)\n",
    "\n",
    "    with create_file_writer(f\"{LOG_BASEPATH}/hparam_tuning\").as_default():\n",
    "        hp.hparams_config(\n",
    "            hparams=hparams,\n",
    "            metrics=[hp.Metric(TARGET_METRIC, display_name=TARGET_METRIC)],\n",
    "        )\n",
    "\n",
    "    start_index = 0\n",
    "    best_loss = np.inf\n",
    "    best_metric = -np.inf\n",
    "    best_params = None\n",
    "    checkpoint = _load_checkpoint(checkpoint_file)\n",
    "    if checkpoint:\n",
    "        start_index = checkpoint['next_index']\n",
    "        best_loss = checkpoint['best_loss']\n",
    "        best_metric = checkpoint['best_metric']\n",
    "        best_params = checkpoint['best_params']\n",
    "\n",
    "    grid = list(ParameterGrid({h.name: h.domain.values for h in hparams}))\n",
    "    for index, hp_values in enumerate(tqdm(grid[start_index:], desc=\"Grid Search..\"), start=start_index):\n",
    "        lr = hp_values[\"learning_rate\"]\n",
    "        conv_layers=hp_values[\"convolutions\"]\n",
    "        max_dilation=hp_values[\"dilation_rate\"]\n",
    "        filters=hp_values[\"filters\"]\n",
    "        kernel_size=hp_values[\"kernel_size\"]\n",
    "        reg_param=hp_values[\"reg_weight\"]\n",
    "        dropout_rate=hp_values[\"dropout_rate\"]\n",
    "        dense_units=hp_values[\"dense_units\"]\n",
    "        dense_layers=hp_values[\"dense_depth\"]\n",
    "\n",
    "        model, history = build_cnn(input_shape,\n",
    "                                   train_dataset, test_dataset=test_dataset,\n",
    "                                    lr=lr,\n",
    "                                    lr_min=LEARN_RATE_MIN,\n",
    "                                    target_metric=TARGET_METRIC,\n",
    "                                    conv_layers=conv_layers,\n",
    "                                    max_dilation=max_dilation,\n",
    "                                    filters=filters,\n",
    "                                    kernel_size=kernel_size,\n",
    "                                    reg_param=reg_param,\n",
    "                                    dropout_rate=dropout_rate,\n",
    "                                    dense_units=dense_units,\n",
    "                                    dense_layers=dense_layers)\n",
    "\n",
    "        history_dict = history.history\n",
    "        loss = history_dict[f\"val_loss\"][-1]\n",
    "        metric = history_dict[f\"val_{TARGET_METRIC}\"][-1]\n",
    "        if (metric > best_metric):\n",
    "            best_history = history\n",
    "            best_loss = loss\n",
    "            best_metric = metric\n",
    "            best_model = model\n",
    "            best_params = hp_values\n",
    "            other_metrics = {\n",
    "                f\"{TARGET_METRIC}\": history_dict[f\"{TARGET_METRIC}\"][-1],\n",
    "                f\"v_{TARGET_METRIC}\": history_dict[f\"val_{TARGET_METRIC}\"][-1],\n",
    "                'ba': history_dict[\"ba\"][-1],\n",
    "                'v_ba': history_dict[\"val_ba\"][-1],\n",
    "            }\n",
    "            _save_best_params(best_params, best_loss, best_metric, other_metrics, file_name)\n",
    "        checkpoint_state = {\n",
    "            'next_index': index + 1,\n",
    "            'best_loss': best_loss,\n",
    "            'best_metric': best_metric,\n",
    "            'best_params': best_params\n",
    "        }\n",
    "        _save_checkpoint(checkpoint_state, checkpoint_file)\n",
    "    return best_model, best_history, best_params, best_loss, best_metric\n",
    "\n",
    "PARAM_SEARCH = False\n",
    "if PARAM_SEARCH:\n",
    "    with strategy.scope():\n",
    "        model, history, best_params, best_loss, best_metric = grid_search_build_cnn(INPUT_SHAPE, train_dataset, val_dataset)\n",
    "        print(best_params)\n",
    "        print(best_metric)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5117138,
     "sourceId": 8561110,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 180912526,
     "sourceType": "kernelVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9944.673694,
   "end_time": "2024-06-02T00:33:34.203396",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-01T21:47:49.529702",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
