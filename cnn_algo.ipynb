{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"143f9c02-8d86-484a-b4c2-eb1317289f2a","_uuid":"068dcfb3-c368-468d-8410-aea88bc0b181","id":"oaDoHbxVH0CW"},"source":["# CNN"]},{"cell_type":"markdown","metadata":{"_cell_guid":"b5ba98a0-9590-4ccd-b238-cfae63d19770","_uuid":"6a6076dd-8ce5-47e2-8913-74dcaa2eacf0","id":"z_cBqdYOoY5S"},"source":["## Notebook's Environment"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"44c8b09f-6f40-410d-aa3c-89b119fb2456","_uuid":"56c0c199-418e-4fa2-a71a-30d54c3a8b2c","collapsed":false,"id":"eETPYJLiMU-b","jupyter":{"outputs_hidden":false},"outputId":"49f77cf0-e6a3-44d8-9dae-05a929fa4804","trusted":true},"outputs":[],"source":["INSTALL_DEPS = False\n","if INSTALL_DEPS:\n","  %pip install matplotlib==3.8.3\n","  %pip installnumpy==1.26.4\n","  %pip installpandas==2.2.1\n","  %pip installpandas_market_calendars==4.4.0\n","  %pip installpytz==2024.1\n","  %pip installscipy==1.12.0\n","  %pip installta==0.11.0\n","  %pip installyfinance==0.2.37\n","\n","!python --version"]},{"cell_type":"markdown","metadata":{},"source":["## Cloud Environment Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cf2e55fb-0872-49df-ae06-aa49505f9474","_uuid":"ccc8fcee-37e2-48b5-8501-6285d13e13cd","collapsed":false,"id":"Q4-GoceIIfT_","jupyter":{"outputs_hidden":false},"outputId":"7dcb11f2-d20e-4714-e4fe-f9895dc22aac","trusted":true},"outputs":[],"source":["import os\n","import sys\n","import warnings\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","IN_KAGGLE = IN_COLAB = False\n","try:\n","    # https://www.tensorflow.org/install/pip#windows-wsl2\n","    import google.colab\n","    from google.colab import drive\n","\n","    drive.mount(\"/content/drive\")\n","    DATA_PATH = \"/content/drive/MyDrive/EDT dataset\"\n","    MODEL_PATH = \"/content/drive/MyDrive/models\"\n","    IN_COLAB = True\n","    print(\"Colab!\")\n","except:\n","    IN_COLAB = False\n","if \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ and not IN_COLAB:\n","    print(\"Running in Kaggle...\")\n","    for dirname, _, filenames in os.walk(\"/kaggle/input\"):\n","        for filename in filenames:\n","            print(os.path.join(dirname, filename))\n","    MODEL_PATH = \"./models\"\n","    DATA_PATH = \"/kaggle/input/\"\n","    IN_KAGGLE = True\n","    print(\"Kaggle!\")\n","elif not IN_COLAB:\n","    IN_KAGGLE = False\n","    MODEL_PATH = \"./models\"\n","    DATA_PATH = \"./data/\"\n","    print(\"running localhost!\")"]},{"cell_type":"markdown","metadata":{},"source":["# Instruments"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from constants import *\n","\n","TARGET_FUT, INTERVAL"]},{"cell_type":"markdown","metadata":{},"source":["## Data Load"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","filename = f\"{DATA_PATH}{os.sep}futures_{INTERVAL}.csv\"\n","print(filename)\n","futs_df = pd.read_csv(filename, index_col=\"Date\", parse_dates=True)\n","\n","print(futs_df.shape)\n","futs_df.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(12, 4))\n","\n","plt.plot(futs_df[f'{TARGET_FUT}_Close'], label=f'{TARGET_FUT} Close', alpha=0.7)\n","plt.title(f'{TARGET_FUT} Price')\n","plt.xlabel('Date')\n","plt.ylabel('Price')\n","plt.legend()\n","plt.grid(True)\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Prepare the Data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from signals import dynamic_support_resistance, kalman_backtest, signal_kf_bollinger_bands, signal_tsmom\n","from quant_equations import get_ou, modulate_std\n","from tqdm import tqdm\n","\n","UNIVERSE_COLS = set()\n","\n","def augment_ts(df, target_close, target_high, target_low, target_volume, interval):\n","    hl, h = get_ou(df, target_close)\n","    window = abs(hl)\n","    mod_std = modulate_std(h)\n","\n","    mom_df = signal_tsmom(df, target_close, int(window*1.5), contra_lookback=window//2, std_threshold=mod_std)\n","    bb_df = signal_kf_bollinger_bands(df, target_close, target_volume, std_factor=mod_std)\n","\n","    spread = bb_df[\"%B\"].bfill().ffill()\n","    volumes = df[target_volume].to_numpy()\n","    prices = df[target_close].to_numpy()\n","\n","    assert not np.isnan(spread).any() and not np.isnan(volumes).any()\n","\n","    sr_df, _, _ = dynamic_support_resistance(df, target_close, target_high, target_low, window_size=hl)\n","    kf_df, _ = kalman_backtest(spread, volumes, prices, period=interval)\n","    aug_ts_df = pd.concat([sr_df, kf_df, bb_df, mom_df], axis=1).bfill().ffill()\n","\n","    return aug_ts_df\n","\n","def process_exog(futures, futs_df, universe_cols=UNIVERSE_COLS):\n","    futs_exog_ts = []\n","    for f in tqdm(futures, desc=\"process_exog\"):\n","        fut_df = futs_df.filter(regex=f\"{f}_.*\")\n","\n","        universe_cols.update(fut_df.columns.tolist())\n","\n","        train_df = fut_df\n","        futs_exog_ts.append(train_df)\n","\n","    futs_exog_df = pd.concat(futs_exog_ts, axis=1)\n","\n","    return futs_exog_df\n","\n","def process_futures(futures, futs_df, futs_exog_df, train_size, interval, universe_cols=UNIVERSE_COLS):\n","    training_ts = []\n","    val_ts = []\n","    for f in tqdm(futures, desc=\"process_futures\"):\n","        fut_df = futs_df.filter(regex=f\"{f}_.*\")\n","        fut_df.columns = fut_df.columns.str.replace(f\"{f}_\", \"\", regex=False)\n","\n","        fut_df = pd.concat([fut_df, futs_exog_df], axis=1)\n","\n","        target_close = f\"Close\"\n","        target_high = f\"High\"\n","        target_low = f\"Low\"\n","        target_volume = f\"Volume\"\n","\n","        if universe_cols is not None:\n","            # For utility, we have all futures columns.\n","            universe_cols.update(fut_df.columns.tolist())\n","\n","        train_df = augment_ts(fut_df.iloc[:train_size], target_close, target_high, target_low, target_volume, interval)\n","        test_df = augment_ts(fut_df.iloc[train_size:], target_close, target_high, target_low, target_volume, interval)\n","        training_ts.append(train_df.reset_index(drop=True))\n","        val_ts.append(test_df.reset_index(drop=True))\n","\n","    return training_ts, val_ts\n","\n","TEST_SPLIT = 0.6\n","TRAIN_SIZE = int(len(futs_df) * TEST_SPLIT)\n","\n","futs_exog_df = process_exog(MARKET_FUTS, futs_df)\n","train_agri_ts, val_agri_ts = process_futures(AGRI_FUTS, futs_df, futs_exog_df, TRAIN_SIZE, INTERVAL)\n","# Stacking the lists of dataframes into single dataframes\n","train_ts_df = pd.concat([df.reset_index(drop=True) for df in train_agri_ts], axis=0, ignore_index=True).dropna()\n","test_ts_df = pd.concat([df.reset_index(drop=True) for df in val_agri_ts], axis=0, ignore_index=True).dropna()\n","\n","train_ts_df.tail(5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import FunctionTransformer, MinMaxScaler, normalize\n","from sklearn.model_selection import ParameterGrid, TimeSeriesSplit\n","from sklearn.metrics import (\n","    accuracy_score, precision_score, recall_score,\n","    fbeta_score, roc_auc_score, roc_curve, auc\n",")\n","\n","\n","PREDICTION_HORIZON = 1\n","WINDOW  = 10\n","\n","def create_features_df(data_df):\n","    def _get_first_difference(data_df):\n","        return data_df.pct_change().bfill()\n","\n","    def _get_log_returns(data_df):\n","        return np.log(data_df / data_df.shift(1)).fillna(0)\n","\n","    price_transform = FunctionTransformer(_get_first_difference)\n","    data_df = price_transform.fit_transform(data_df)\n","\n","    return data_df.fillna(0)\n","\n","def prepare_data(ts_df, label_df=None, to_normalize=True):\n","    data_df = create_features_df(ts_df)\n","    if to_normalize:\n","        data_df = data_df.replace([np.inf, -np.inf], np.nan).interpolate()\n","        assert not data_df.isna().any()\n","        data_df = normalize(data_df, norm=\"l2\")\n","\n","    if label_df is not None:\n","        data_df = pd.concat([data_df, label_df], axis=1)\n","\n","    return data_df.dropna(axis=0)\n","\n","def prepare_windows(\n","    data_df,\n","    label_df,\n","    exog_ts,\n","    window_size=WINDOW,\n","    horizon=PREDICTION_HORIZON,\n","):\n","    assert len(data_df) > 1\n","    X, Xexog, y = [], [], []\n","    for i in tqdm(\n","        range(len(data_df) - window_size - horizon + 1), desc=f\"Encoding Widows of {window_size} with {horizon} horizon.\"\n","    ):\n","        input_window = data_df.iloc[i : i + window_size].values\n","        X.append(input_window)\n","        if exog_ts is not None:\n","            input_window = data_df[exog_ts].iloc[i : i + window_size].values\n","            Xexog.append(input_window)\n","        if label_df is not None:\n","            target_window = label_df.iloc[i + window_size : i + window_size + horizon].values\n","            y.append(target_window)\n","\n","    return np.array(X), np.array(Xexog), np.array(y)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import shutil\n","\n","import tensorflow as tf\n","from tensorflow.keras.layers import (\n","    SpatialDropout1D,\n","    Dense,\n","    Conv1D,\n","    Layer,\n","    Add,\n","    Input,\n","    Concatenate,\n","    Flatten,\n","    MultiHeadAttention,\n",")\n","from tensorflow.keras import Model\n","from tensorboard import program\n","from tensorboard.plugins.hparams import api as hp\n","from tensorflow.keras.losses import BinaryCrossentropy, BinaryFocalCrossentropy\n","from tensorflow.keras.metrics import AUC, BinaryAccuracy, Recall, Precision\n","from tensorflow.keras.regularizers import L1L2\n","from tensorflow.keras.callbacks import EarlyStopping, TensorBoard,ModelCheckpoint,ReduceLROnPlateau,LambdaCallback\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.summary import create_file_writer\n","from tensorflow.math import confusion_matrix\n","\n","NONLINEAR_ACTIVATION = 'tanh'\n","NONLINEAR_ACTIVATION_DENSE = \"tanh\"\n","NONLINEAR_OUTPUT_ACTIVATION = \"sigmoid\"\n","MODEL_NAME = \"TCN\"\n","MODEL_DIR = f\"../models/{MODEL_NAME}\"\n","IMAGES_DIR = f\"../images/{MODEL_NAME}/images\"\n","LOG_BASEPATH = f\"../logs/{MODEL_NAME}/tb\"\n","\n","OOS_SPLIT = 0.1\n","VAL_SPLIT = 0.20\n","EPOCHS = 300\n","PATIENCE_EPOCHS = 15\n","BATCH_SIZE = 124\n","GRID_SEARCH_TRAIN = False\n","CV_MODEL = True\n","CV_SPLITS = 3\n","\n","MAX_FILTER = 512\n","MIN_FILTER = 32\n","FILTERS = [MIN_FILTER, MIN_FILTER*2]\n","HIDDEN_DENSE = [WINDOW]\n","BIAS = True\n","DROPRATE = 0.25\n","POOL_SIZE = 8\n","KERNEL_SIZE = 2\n","DILATION_RATE = 1\n","REG_WEIGHTS = 0.005\n","LEARN_RATE = 0.0025\n","\n","ERROR_ALPHA = 0.8 # 0.5 > gives more weight to positive class errors\n","ERROR_GAMMA = 2.4 # loss contribution from easy examples. 0 > focus on hard examples.\n","CLASS_WEIGHTS = None\n","TARGET_METRIC = \"auc\"\n","LOSS = BinaryFocalCrossentropy(apply_class_balancing=True, from_logits=True, alpha=ERROR_ALPHA, gamma=ERROR_GAMMA)\n","METRICS = [AUC(name=TARGET_METRIC, from_logits=True, label_weights=CLASS_WEIGHTS),\n","            AUC(name=\"pr_auc\", curve=\"PR\", from_logits=True, label_weights=CLASS_WEIGHTS),\n","            BinaryCrossentropy(from_logits=True),\n","            BinaryAccuracy(name='accuracy'),\n","            Precision(name='precision'),\n","            Recall(name='recall')]\n","\n","tf.keras.saving.get_custom_objects().clear()\n","\n","@tf.keras.saving.register_keras_serializable()\n","class TCNBlock(Layer):\n","    \"\"\"\n","    TCN Residual Block that uses zero-padding to maintain `steps` value of the ouput equal to the one in the input.\n","    Residual Block is obtained by stacking togeather (2x) the following:\n","        - 1D Dilated Convolution\n","        - ReLu\n","        - Spatial Dropout\n","    And adding the input after trasnforming it with a 1x1 Conv\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        filters=1,\n","        kernel_size=2,\n","        dilation_rate=1,\n","        kernel_initializer=\"glorot_normal\",\n","        bias_initializer=\"glorot_normal\",\n","        kernel_regularizer=None,\n","        bias_regularizer=None,\n","        use_bias=False,\n","        dropout_rate=0.0,\n","        layer_id=None,\n","        **kwargs,\n","    ):\n","        super(TCNBlock, self).__init__(**kwargs)\n","        assert dilation_rate is not None and dilation_rate > 0 and filters > 0 and kernel_size > 0\n","\n","        self.filters = filters\n","        self.kernel_size = kernel_size\n","        self.dilation_rate = dilation_rate\n","        self.kernel_initializer = kernel_initializer\n","        self.bias_initializer = bias_initializer\n","        self.kernel_regularizer = kernel_regularizer\n","        self.bias_regularizer = bias_regularizer\n","        self.use_bias = use_bias\n","        self.dropout_rate = dropout_rate\n","        self.layer_id = str(layer_id)\n","\n","    def get_config(self):\n","        config = super(TCNBlock, self).get_config()\n","        config.update({\n","            'filters': self.filters,\n","            'kernel_size': self.kernel_size,\n","            'dilation_rate': self.dilation_rate,\n","            'kernel_initializer': self.kernel_initializer,\n","            'bias_initializer': self.bias_initializer,\n","            'kernel_regularizer': self.kernel_regularizer,\n","            'bias_regularizer': self.bias_regularizer,\n","            'use_bias': self.use_bias,\n","            'dropout_rate': self.dropout_rate,\n","        })\n","        return config\n","\n","    def build(self, inputs):\n","        self.conv1 = Conv1D(\n","            filters=self.filters,\n","            kernel_size=self.kernel_size,\n","            use_bias=self.use_bias,\n","            bias_initializer=self.bias_initializer,\n","            bias_regularizer=self.bias_regularizer,\n","            kernel_initializer=self.kernel_initializer,\n","            kernel_regularizer=self.kernel_regularizer,\n","            padding=\"causal\",\n","            dilation_rate=self.dilation_rate,\n","            activation=NONLINEAR_ACTIVATION,\n","            name=f\"Conv1D_1_{self.layer_id}\"\n","        )\n","        # Spatial dropout is specific to convolutions by dropping an entire timewindow,\n","        # not to rely too heavily on specific features detected by the kernels.\n","        self.dropout1 = SpatialDropout1D(\n","            self.dropout_rate, trainable=True, name=f\"SpatialDropout1D_1_{self.layer_id}\"\n","        )\n","        # Capture a higher order feature set from the previous convolution\n","        self.conv2 = Conv1D(\n","            filters=self.filters,\n","            kernel_size=self.kernel_size,\n","            use_bias=self.use_bias,\n","            bias_initializer=self.bias_initializer,\n","            bias_regularizer=self.bias_regularizer,\n","            kernel_initializer=self.kernel_initializer,\n","            kernel_regularizer=self.kernel_regularizer,\n","            padding=\"causal\",\n","            dilation_rate=self.dilation_rate,\n","            activation=NONLINEAR_ACTIVATION,\n","            name=f\"Conv1D_2_{self.layer_id}\"\n","        )\n","        self.dropout2 = SpatialDropout1D(\n","            self.dropout_rate, trainable=True, name=f\"SpatialDropout1D_2_{self.layer_id}\"\n","        )\n","        # The skip connection is an addition of the input to the block with the output of the second dropout layer.\n","        # Solves vanishing gradient, carries info from earlier layers to later layers, allowing gradients to flow across this alternative path.\n","        # Does not learn direct mappings, but differences (residuals) while keeping temporal context.\n","        # Note how it keeps dims intact with kernel 1.\n","        self.skip_out = Conv1D(\n","            filters=self.filters,\n","            kernel_size=1,\n","            activation=\"linear\",\n","            padding=\"same\",\n","            name=f\"Conv1D_skipconnection_{self.layer_id}\",\n","        )\n","        # This is the elementwise add for the residual connection and Conv1d 2's output\n","        self.residual_out = Add(name=f\"residual_Add_{self.layer_id}\")\n","\n","    def call(self, inputs):\n","        x = self.conv1(inputs)\n","        x = self.dropout1(x)\n","        x = self.conv2(x)\n","        x = self.dropout2(x)\n","\n","        # Residual output by adding the inputs back\n","        skip_out_x = self.skip_out(inputs)\n","        x = self.residual_out([x, skip_out_x])\n","        return x, skip_out_x\n","\n","\n","\n","@tf.keras.saving.register_keras_serializable()\n","class ConditionalBlock(Layer):\n","    \"\"\"\n","    TCN condtioning Block that conditions a target timeseries to exogenous timeserieses.\n","    The Block is obtained by stacking togeather the following:\n","        - 1D Dilated Convolution for the main TS.\n","        - 1D Dilated Convolution for the exog TSs.\n","        - 1D Dilated skip layer for both to retain history.\n","        - ReLu\n","        - Spatial Dropout\n","    And adding the input after trasnforming it with a 1x1 Conv\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        filters=1,\n","        kernel_size=2,\n","        kernel_initializer=\"glorot_normal\",\n","        bias_initializer=\"glorot_normal\",\n","        kernel_regularizer=None,\n","        bias_regularizer=None,\n","        use_bias=False,\n","        dropout_rate=0.01,\n","        layer_id=None,\n","        **kwargs,\n","    ):\n","        super(ConditionalBlock, self).__init__(**kwargs)\n","\n","        assert filters > 0 and kernel_size > 0\n","\n","        self.filters = filters\n","        self.kernel_size = kernel_size\n","        self.kernel_initializer = kernel_initializer\n","        self.bias_initializer = bias_initializer\n","        self.kernel_regularizer = kernel_regularizer\n","        self.bias_regularizer = bias_regularizer\n","        self.use_bias = use_bias\n","        self.dropout_rate = dropout_rate\n","        self.layer_id = str(layer_id)\n","\n","    def get_config(self):\n","        config = super(ConditionalBlock, self).get_config()\n","        config.update({\n","            'filters': self.filters,\n","            'kernel_size': self.kernel_size,\n","            'kernel_initializer': self.kernel_initializer,\n","            'bias_initializer': self.bias_initializer,\n","            'kernel_regularizer': self.kernel_regularizer,\n","            'bias_regularizer': self.bias_regularizer,\n","            'use_bias': self.use_bias,\n","            'dropout_rate': self.dropout_rate,\n","            #'id': self.layer_id\n","        })\n","        return config\n","\n","    def build(self, inputs):\n","        self.main_conv = Conv1D(\n","            filters=self.filters,\n","            kernel_size=self.kernel_size,\n","            use_bias=self.use_bias,\n","            bias_initializer=self.bias_initializer,\n","            bias_regularizer=self.bias_regularizer,\n","            kernel_initializer=self.kernel_initializer,\n","            kernel_regularizer=self.kernel_regularizer,\n","            padding=\"causal\",\n","            activation=NONLINEAR_ACTIVATION,\n","            name=f\"Conv1D_Conditional_1\",\n","        )\n","        self.dropout1 = SpatialDropout1D(\n","            self.dropout_rate, trainable=True, name=f\"SpatialDropout1D_1_{self.layer_id}\"\n","        )\n","        self.main_skip_conn = Conv1D(\n","            filters=self.filters,\n","            kernel_size=1,\n","            activation=\"linear\",\n","            padding=\"same\",\n","            name=f\"Skip_Conditional_1\",\n","        )\n","        self.cond_conv = Conv1D(\n","            filters=self.filters,\n","            kernel_size=self.kernel_size,\n","            use_bias=self.use_bias,\n","            bias_initializer=self.bias_initializer,\n","            bias_regularizer=self.bias_regularizer,\n","            kernel_initializer=self.kernel_initializer,\n","            kernel_regularizer=self.kernel_regularizer,\n","            padding=\"causal\",\n","            activation=NONLINEAR_ACTIVATION,\n","            name=f\"Conv1D_Conditional_2\",\n","        )\n","        self.cond_skip_conn = Conv1D(\n","            filters=self.filters,\n","            kernel_size=1,\n","            activation=\"linear\",\n","            padding=\"same\",\n","            name=f\"Skip_Conditional_2\",\n","        )\n","        self.dropout2 = SpatialDropout1D(\n","            self.dropout_rate, trainable=True, name=f\"SpatialDropout1D_2_{self.layer_id}\"\n","        )\n","\n","    def call(self, inputs):\n","        main_input, cond_input = inputs[0], inputs[1] if len(inputs) > 1 else None\n","\n","        x = self.main_conv(main_input)\n","        x = self.dropout1(x)\n","        skip_out_x = self.main_skip_conn(main_input)\n","        x = Add()([x, skip_out_x])\n","        if cond_input is not None:\n","            cond_x = self.cond_conv(cond_input)\n","            cond_x = self.dropout2(cond_x)\n","            cond_skip_out_x = self.cond_skip_conn(cond_input)\n","            cond_x = Add()([cond_x, cond_skip_out_x])\n","\n","            x = Concatenate(axis=-1)([x, cond_x])\n","        return x\n","\n","def TCN(\n","    input_shape,\n","    dense_units=None,\n","    conditioning_shapes=None,\n","    output_horizon=1,\n","    filters=[32],\n","    kernel_size=2,\n","    dilation_rate=2,\n","    kernel_initializer=\"glorot_normal\",\n","    bias_initializer=\"glorot_normal\",\n","    kernel_regularizer=None,\n","    bias_regularizer=None,\n","    use_bias=False,\n","    dropout_rate=0.01,\n","):\n","    \"\"\"\n","    Tensorflow TCN Model builder.\n","    see: https://www.tensorflow.org/api_docs/python/tf/keras/Model\n","    see: https://www.tensorflow.org/guide/keras/making_new_layers_and_models_via_subclassing#the_model_class\n","    see: https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/L2\n","\n","    :param layers: int\n","        Number of layers for the network. Defaults to 1 layer.\n","    :param filters: int\n","        the number of output filters in the convolution. Defaults to 32.\n","    :param kernel_size: int or tuple\n","        the length of the 1D convolution window\n","    :param dilation_rate: int\n","        the dilation rate to use for dilated convolution. Defaults to 1.\n","    :param output_horizon: int\n","        the output horizon.\n","    \"\"\"\n","    main_input = Input(shape=input_shape, name=\"main_input\")\n","    cond_input = (\n","        Input(shape=conditioning_shapes, name=\"exog_input\")\n","        if conditioning_shapes is not None and len(conditioning_shapes) > 0\n","        else None\n","    )\n","    x = main_input\n","    if cond_input is not None:\n","        x = ConditionalBlock(\n","            filters=filters[0],\n","            kernel_size=kernel_size,\n","            kernel_initializer=kernel_initializer,\n","            bias_initializer=bias_initializer,\n","            kernel_regularizer=kernel_regularizer,\n","            bias_regularizer=bias_regularizer,\n","            use_bias=use_bias,\n","            dropout_rate=dropout_rate,\n","        )([main_input] + [cond_input])\n","\n","    skip_connections = []\n","    for i, filter in enumerate(filters):\n","        # x_att = AttentionBlock(filters=filter)(x)\n","        x, x_skip = TCNBlock(\n","            filters=filter,\n","            kernel_size=kernel_size,\n","            dilation_rate=dilation_rate ** (i + 1),\n","            kernel_initializer=kernel_initializer,\n","            bias_initializer=bias_initializer,\n","            kernel_regularizer=kernel_regularizer,\n","            bias_regularizer=bias_regularizer,\n","            use_bias=use_bias,\n","            dropout_rate=dropout_rate,\n","            layer_id=i,\n","        )(x)\n","        #skip_connections.append(x_att)\n","        skip_connections.append(x_skip)\n","    if skip_connections:\n","        skip_connections.append(x)\n","        aggregated = Concatenate(axis=-1, name=f\"Final_Residuals\")(skip_connections)\n","        aggregated = Conv1D(filters[-1], kernel_size=1, activation=\"linear\", padding='same')(aggregated)\n","    if dense_units:\n","        # Dense networks for deep learning ifrequired.\n","        x = Flatten()(x)\n","        # First layer\n","        x = Dense(dense_units[0], input_shape=input_shape, activation=NONLINEAR_ACTIVATION_DENSE, name=f\"Dense_0\")(x)\n","        for i, units  in enumerate(dense_units, start=1):\n","            x = Dense(units , activation=NONLINEAR_ACTIVATION_DENSE, name=f\"Dense__{i}\")(x)\n","        # Last layer\n","        x = Dense(output_horizon, activation=NONLINEAR_OUTPUT_ACTIVATION, name=f\"Dense_Classifier\")(x)\n","    else:\n","        x = Conv1D(filters=output_horizon, kernel_size=1, padding=\"causal\", activation=NONLINEAR_OUTPUT_ACTIVATION,name=f\"Conv_Classifier\")(x)\n","    model = Model(\n","        inputs=[main_input, cond_input] if cond_input is not None else [main_input],\n","        outputs=x,\n","        name=\"TCN_Conditional_Model\",\n","    )\n","    return model\n","\n","\n","def start_tensorboard(log_base=LOG_BASEPATH, del_logs=True):\n","    if del_logs and os.path.exists(log_base):\n","        assert os.path.isdir(log_base)\n","        shutil.rmtree(log_base)\n","\n","    tb = program.TensorBoard()\n","    tb.configure(argv=[None, '--logdir', log_base, '--bind_all'])\n","    url = tb.launch()\n","\n","def build_tcn(\n","    input_shape,\n","    X, y,\n","    Xt=None, yt=None,\n","    conditioning_shapes=None,\n","    val_split=VAL_SPLIT,\n","    output_horizon= PREDICTION_HORIZON,\n","    filters= FILTERS,\n","    kernel_size= KERNEL_SIZE,\n","    dilation_rate= DILATION_RATE,\n","    kernel_regularizer=L1L2(l1= REG_WEIGHTS, l2=REG_WEIGHTS//10),\n","    bias_regularizer=L1L2(l1= REG_WEIGHTS, l2=REG_WEIGHTS//10),\n","    dropout_rate=DROPRATE,\n","    dense_units=HIDDEN_DENSE,\n","    lr=LEARN_RATE,\n","    patience=PATIENCE_EPOCHS,\n","    epochs=EPOCHS,\n","    batch_size=BATCH_SIZE,\n","    use_bias=BIAS,\n","    loss=LOSS,\n","    tb=False,\n","    classification=True,\n","    weighted=True,\n","):\n","    def _plot_confusion_matrix(cm, labels, cm2=None, labels2=None):\n","        plt.figure(figsize=(8 if cm2 is not None else 4, 4))\n","        if cm2 is not None:\n","            plt.subplot(1, 2, 1)\n","        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Accent)\n","\n","        df_cm = pd.DataFrame((cm / np.sum(cm, axis=1)[:, None])*100, index=[i for i in labels], columns=[i for i in labels])\n","        cm_plot1 = sns.heatmap(df_cm, annot=True,  fmt=\".2f\", cmap='Blues', xticklabels=labels, yticklabels=labels).get_figure()\n","        plt.xlabel('Predicted Labels')\n","        plt.ylabel('True Labels')\n","        plt.title('Confusion Matrix 1')\n","        tick_marks = np.arange(len(labels))\n","        plt.xticks(tick_marks, labels, rotation=45)\n","        plt.yticks(tick_marks, labels)\n","\n","        cm_plot2=None\n","        if cm2 is not None:\n","            plt.subplot(1, 2, 2)\n","            df_cm = pd.DataFrame((cm2 / np.sum(cm2, axis=1)[:, None])*100, index=[i for i in labels2], columns=[i for i in labels2])\n","            cm_plot12 = sns.heatmap(df_cm, annot=True,  fmt=\".2f\", cmap='Reds', xticklabels=labels, yticklabels=labels).get_figure()\n","            plt.xlabel('Predicted Labels')\n","            plt.title('Confusion Matrix 2')\n","        plt.tight_layout()\n","        return cm_plot1, cm_plot2\n","\n","    def _log_confusion_matrix(epoch, logs):\n","        def _plot_to_image(figure):\n","            \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n","            returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n","            buf = io.BytesIO()\n","            plt.savefig(buf, format='png')\n","            plt.close(figure)\n","            buf.seek(0)\n","            image = tf.image.decode_png(buf.getvalue(), channels=4)\n","            image = tf.expand_dims(image, 0)\n","            return image\n","        # model is global as is XT and yt - discretize for CM\n","        assert Xt is not None and len(Xt) > 1 and len(yt) > 1\n","        ypred = model.predict(Xt)\n","        y_discrete = (ypred.flatten() > 0.5).astype(int)\n","        cm = confusion_matrix(yt.flatten(), y_discrete)\n","        figure, _ = _plot_confusion_matrix(cm, labels=[1,0])\n","        cm_image = _plot_to_image(figure)\n","\n","        file_writer_cm = create_file_writer(LOG_BASEPATH)\n","        with file_writer_cm.as_default():\n","            tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n","\n","    assert len(X) > 1 and len(y) > 1 and input_shape is not None\n","    global model, globalXt, globalyt\n","    globalXt = Xt\n","    globalyt = yt\n","\n","    model = TCN(\n","        input_shape=input_shape,\n","        conditioning_shapes=conditioning_shapes,\n","        dense_units=dense_units,\n","        output_horizon=output_horizon,\n","        filters=filters,\n","        kernel_size=kernel_size,\n","        dilation_rate=dilation_rate,\n","        kernel_regularizer=kernel_regularizer,\n","        bias_regularizer=bias_regularizer,\n","        use_bias=use_bias,\n","        dropout_rate=dropout_rate,\n","    )\n","    if weighted:\n","        assert classification\n","        y_flat = y.flatten()\n","        weight_for_0 = (1 / np.sum(y_flat == 0)) * (len(y_flat) / 2.0)\n","        weight_for_1 = (1 / np.sum(y_flat == 1)) * (len(y_flat)  / 2.0)\n","        assert weight_for_0 > 0 and weight_for_1 > 0\n","        CLASS_WEIGHTS = {0: weight_for_0, 1: weight_for_1}\n","\n","    model.compile(loss=loss, optimizer=Adam(learning_rate=lr), metrics=METRICS)\n","    callbacks = [EarlyStopping(\n","                    patience=patience,\n","                    monitor=f\"val_{TARGET_METRIC}\",\n","                    restore_best_weights=True,\n","                ),\n","                ReduceLROnPlateau(\n","                    monitor=f\"val_{TARGET_METRIC}\",\n","                    factor=0.3,\n","                    patience=patience//2,\n","                    verbose=1 if tb else 0,\n","                    min_delta=0.00001,\n","                )]\n","    if tb:\n","        callbacks.append(TensorBoard(log_dir=LOG_BASEPATH,\n","                                    histogram_freq=1,\n","                                    write_graph=True,\n","                                    write_images=True,\n","                                    update_freq='epoch',\n","                                    profile_batch=2,\n","                                    embeddings_freq=1))\n","    if tb and classification:\n","        callbacks.append(LambdaCallback(on_epoch_end=_log_confusion_matrix))\n","    if Xt is not None:\n","        assert len(Xt) > 1 and len(yt) > 1\n","        history = model.fit(\n","            X,\n","            y,\n","            validation_data=(Xt, yt),\n","            epochs=epochs,\n","            batch_size=batch_size,\n","            callbacks=callbacks,\n","            verbose=1 if tb else 0,\n","        )\n","    else:\n","        assert val_split > 0 and  Xt is None and yt is None\n","        history = model.fit(\n","            X,\n","            y,\n","            validation_split=val_split,\n","            epochs=epochs,\n","            batch_size=batch_size,\n","            callbacks=callbacks,\n","            verbose=1 if tb else 0,\n","        )\n","    return model, history\n","\n","build_tcn(input_shape, X, y, Xt=None, yt=None)"]}],"metadata":{"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"datasetId":4755137,"sourceId":8061237,"sourceType":"datasetVersion"}],"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":4}
