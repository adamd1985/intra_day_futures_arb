{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"143f9c02-8d86-484a-b4c2-eb1317289f2a","_uuid":"068dcfb3-c368-468d-8410-aea88bc0b181","id":"oaDoHbxVH0CW"},"source":["# Statistical Algos"]},{"cell_type":"markdown","metadata":{"_cell_guid":"b5ba98a0-9590-4ccd-b238-cfae63d19770","_uuid":"6a6076dd-8ce5-47e2-8913-74dcaa2eacf0","id":"z_cBqdYOoY5S"},"source":["## Notebook's Environment"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"44c8b09f-6f40-410d-aa3c-89b119fb2456","_uuid":"56c0c199-418e-4fa2-a71a-30d54c3a8b2c","collapsed":false,"id":"eETPYJLiMU-b","jupyter":{"outputs_hidden":false},"outputId":"49f77cf0-e6a3-44d8-9dae-05a929fa4804","trusted":true},"outputs":[],"source":["INSTALL_DEPS = False\n","if INSTALL_DEPS:\n","  %pip install matplotlib==3.8.3\n","  %pip installnumpy==1.26.4\n","  %pip installpandas==2.2.1\n","  %pip installpandas_market_calendars==4.4.0\n","  %pip installpytz==2024.1\n","  %pip installscipy==1.12.0\n","  %pip installta==0.11.0\n","  %pip installyfinance==0.2.37\n","\n","!python --version"]},{"cell_type":"markdown","metadata":{},"source":["## Cloud Environment Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cf2e55fb-0872-49df-ae06-aa49505f9474","_uuid":"ccc8fcee-37e2-48b5-8501-6285d13e13cd","collapsed":false,"id":"Q4-GoceIIfT_","jupyter":{"outputs_hidden":false},"outputId":"7dcb11f2-d20e-4714-e4fe-f9895dc22aac","trusted":true},"outputs":[],"source":["import os\n","import sys\n","import warnings\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","IN_KAGGLE = IN_COLAB = False\n","try:\n","    # https://www.tensorflow.org/install/pip#windows-wsl2\n","    import google.colab\n","    from google.colab import drive\n","\n","    drive.mount(\"/content/drive\")\n","    DATA_PATH = \"/content/drive/MyDrive/EDT dataset\"\n","    MODEL_PATH = \"/content/drive/MyDrive/models\"\n","    IN_COLAB = True\n","    print(\"Colab!\")\n","except:\n","    IN_COLAB = False\n","if \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ and not IN_COLAB:\n","    print(\"Running in Kaggle...\")\n","    for dirname, _, filenames in os.walk(\"/kaggle/input\"):\n","        for filename in filenames:\n","            print(os.path.join(dirname, filename))\n","    MODEL_PATH = \"./models\"\n","    DATA_PATH = \"/kaggle/input/\"\n","    IN_KAGGLE = True\n","    print(\"Kaggle!\")\n","elif not IN_COLAB:\n","    IN_KAGGLE = False\n","    MODEL_PATH = \"./models\"\n","    DATA_PATH = \"./data/\"\n","    print(\"running localhost!\")"]},{"cell_type":"markdown","metadata":{},"source":["# Instruments"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from constants import *\n","\n","INTERVAL = YFinanceOptions.M15\n","TARGET_FUT=WHEAT_FUT.replace(\"=F\", \"\")\n","\n","TARGET_FUT, INTERVAL"]},{"cell_type":"markdown","metadata":{},"source":["## Data Load"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","filename = f\"{DATA_PATH}{os.sep}futures_{INTERVAL}.csv\"\n","print(filename)\n","futs_df = pd.read_csv(filename, index_col=\"Date\", parse_dates=True)\n","\n","print(futs_df.shape)\n","print(futs_df.columns)\n","futs_df.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(18, 8))\n","\n","plt.plot(futs_df[f'{TARGET_FUT}_Close'], label=f'{TARGET_FUT} Close', alpha=0.7)\n","plt.title(f'{TARGET_FUT} Price')\n","plt.xlabel('Date')\n","plt.ylabel('Price')\n","plt.legend()\n","plt.grid(True)\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["target_fut_df = futs_df[[f\"{TARGET_FUT}_Close\"]]\n","target_fut_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from quant_equations import get_ou, get_annualized_factor, calc_annualized_sharpe, deflated_sharpe_ratio\n","\n","HALF_LIFE, HURST = get_ou(target_fut_df, f\"{TARGET_FUT}_Close\")\n","\n","print(\"Half-Life:\", HALF_LIFE)\n","print(\"Hurst:\", HURST)"]},{"cell_type":"markdown","metadata":{},"source":["# Kalman Filter"]},{"cell_type":"markdown","metadata":{},"source":["A Kalman filter is used to estimate the values of variables cannot be measured directly. \n","\n","Estimating 2 error components in the predicted value $y_i$:\n","1. Mean-reverting error component ($\\epsilon_{mr,t}$): This error corrects itself over time, meaning if it deviates from a certain value, it should return to that value. If not, the structure brokedown.\n","2. Random walk error component ($\\epsilon_{rw,t}$): This error does not correct itself and continues in its last direction, with changes only due to random fluctuations.\n","\n","$y_i$ is defined by:\n","- $C_0$ constant\n","- $X_i$ price at time T, and its coefficient $b$\n","- The systematic error $\\epsilon_{s,t}$, and the errors: $\\epsilon_{mr,t}$, $\\epsilon_{rw,t}$.\n","- $\\epsilon_t$ which is the spread between the $y_t$ observation and its prediction $\\hat{y}$ based on x, consists of the error components listed above.\n","\n","Error equations, have a zero mean noise component:\n","- $\\epsilon_{mr,t}$ is a autoregressive + the noise $\\epsilon_{mrs,t}$, with variance $\\sigma^2_{mr}$\n","- $\\epsilon_{rw,t}$ is a autoregressive + the noise $\\epsilon_{rws,t}$, with variance $\\sigma^2_{rw}$"]},{"cell_type":"markdown","metadata":{},"source":["Kalman is composed of: States, Observations, Transitions\n","\n","$X_t = H_t Z_t + V_t$\n","\n","$Z_t = F_{t-1} Z_{t-1} + G_{t-1} U_{t-1} + W_{t-1}$\n","\n","- Zt is the unboservable state, mapped by Ht to Xt, and translates the internal hidden states.\n","- Xt is the price\n","- Ut is the control paramaters, 0 for this case. Gt linkes Ut to Zt, which is also 0.\n","- Ft-1 is the state change.\n","- Wt and Vt are the noise with their covar matrices Qt, Rt\n","\n","The models equations:\n","\n","- $P_t = F_{t-1} P_{t-1}^+ F_{t-1}^T + Q_{t-1}$\n","  - Predicts the new Error Covar Pt: acurracy of the next prediction.\n","  - Qt-1 is the noise covar. Ft-1 is the state transition.\n","  - Pt-1 is the previous covar, Qt is the noise covar for unreliability.\n","- $P_t^+ = (I - K_t H_t) P_t (I - K_t H_t)^T + K_t R_t K_t^T$\n","  - Update the error covar.\n","  - Pt+ is the new level of uncertaintity.\n","  - Kt is the kalman gain. Ht is he state, Rt is the noise covar, I is ID matrix.\n","- $K_t = P_t^- H_t^T (H_t P_t^- H_t^T + R_t)^{-1}$\n","  - The gain matrix that determines the prediction correctness.\n","  - Small gain == Xt is small, little uncertainty.\n","- $Z_t^- = F_{t-1} Z_{t-1}^+ + G_{t-1} U_{t-1}$\n","  - State update. From prev correct state Zt-t+, Ft-1 state transition and Gt-1 is the control input which is 0.\n","- $Z_t^+ = Z_t^- + K_t (X_t - H_t Z_t^-) = Z_t^-(1 - K_t H_t) + K_tX_t$\n","  - Updates to the corrected state Zt+ after the new data from Xt. Xt-HtZt is the residual."]},{"cell_type":"markdown","metadata":{},"source":["state updates with b coeff $y_t = bx_t + \\epsilon_{mr,t} + \\epsilon_{rw,t}$:\n","$$\n","X_t = \\begin{bmatrix} y_t \\\\ x_t \\end{bmatrix} = \\begin{bmatrix} b & 1 & 1 \\\\ 1 & 0 & 0 \\end{bmatrix}  \\begin{bmatrix} x_t \\\\ \\epsilon_{mr,t} \\\\ \\epsilon_{rw,t} \\end{bmatrix}\n","$$\n","\n","Residual updates, p -1..1 is the mean reversion:\n","\n","$$\n","Z_t = \\begin{bmatrix} x_t \\\\ \\epsilon_{mr,t} \\\\ \\epsilon_{rw,t} \\end{bmatrix} = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & \\rho & 0 \\\\ 0 & 0 & 1 \\end{bmatrix} \\begin{bmatrix} x_{t-1} \\\\ \\epsilon_{mr,t-1} \\\\ \\epsilon_{rw,t-1} \\end{bmatrix} + \\begin{bmatrix} \\epsilon_{xs,t} \\\\ \\epsilon_{mrs,t} \\\\ \\epsilon_{rws,t} \\end{bmatrix}\n","$$ "]},{"cell_type":"markdown","metadata":{},"source":["Assume MR and RW are indepent.\n","\n","Var proportion to MR:\n","$$\n","R^2_{mr} = \\frac{2\\sigma^2_{mr}}{2\\sigma^2_{mr} + (1 + \\rho)\\sigma^2_{rw}}\n","$$\n","\n","Solving for p (mean reverting coeff - speed of adjustment) based on empyrical data:\n","$$\n","\\rho = \\frac{v_1 - 2v_2 + v_3}{2v_1 - v_2}\n","$$\n","Solving for MR std:\n","$$\n","\\sigma^2_{mr} = \\frac{1}{2}\\left(\\frac{\\rho + 1}{\\rho-1}\\right)\\left({v_2-2v_1}\\right)\n","$$\n","\n","$$\n","\\sigma^2_{rw} = \\frac{1}{2} \\left( v_2 - 2 \\sigma^2_{mr} \\right)\n","$$\n","\n","where k is:\n","$$\n","v_k = \\frac{(\\rho^k - 1)^2 + (1 - \\rho^{2k})}{1 - \\rho^2} \\sigma_{mr}^2 + k \\sigma_{rw}^2\n","$$\n","\n","2v1-v2 = 0 is satisfied when ρ = 1, and as ρ < 1,\n","\n","The gain matrix therefore is the influence of MR scaled to RW (K1) and the RW influence (K2):\n","\n","$$\n","K = \\begin{bmatrix} \\frac{2\\sigma_{mr}}{\\sigma_{rw}\\left(\\sqrt{(\\rho+1)^2\\sigma_{rw}^2+4\\sigma_{mr}^2+\\rho\\sigma_{rw}+\\sigma_{rw}}+2\\sigma_{mr}\\right)}\\\\ \\frac{2\\sigma_{rw}}{{\\sqrt{(\\rho+1)^2\\sigma_{rw}^2+4\\sigma_{mr}^2-\\rho\\sigma_{rw}+\\sigma_{rw}}}} \\end{bmatrix} \n","$$\n","\n","When P is high, there is more MR component.\n","\n","- Computational complexity is cubic in the size of the state space\n","- Parameter optimization is non-convex and can thus only find local optima\n","- Inability to cope with non-Gaussian noise\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","## B%\n","\n","- %B is below 0 when price is below the lower band\n","- %B equals 0 when price is at the lower band\n","- %B is between 0 and .50 when price is between the lower and middle band (20-day SMA)\n","- %B is between .50 and 1 when price is between the upper and middle band (20-day SMA)\n","- %B equals 1 when price is at the upper band\n","- %B is above 1 when price is above the upper band"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from pykalman import KalmanFilter # https://github.com/pykalman/pykalman\n","from signals import signal_bollinger_bands\n","from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.metrics import mean_squared_error\n","from tqdm import tqdm\n","import itertools\n","import numpy as np\n","\n","def calculate_variances(spread):\n","    # From the paper, they say V is lagged differences for partial coint.\n","    spread_diff = np.diff(spread, prepend=spread[0])\n","    spread_diff_lag1 = np.roll(spread_diff, 1)[1:]\n","    spread_diff_lag2 = np.roll(spread_diff, 2)[2:]\n","\n","    v1 = np.var(spread_diff)\n","    v2 = np.var(spread_diff_lag1)\n","    v3 = np.var(spread_diff_lag2)\n","\n","    return v1, v2, v3\n","\n","def estimate_parameters(spread):\n","    v1, v2, v3 = calculate_variances(spread)\n","\n","    # formulas provided by the paper\n","    rho = -(v1 - 2*v2 + v3) / (2*v1 - v2)\n","    if v2 - 2*v1 >= 0:\n","        sigma_mr = np.sqrt(((v2 - 2*v1) * (1 + rho)) / (2 * (1 - rho)))\n","    else:\n","        # This happens when its not MR.\n","        sigma_mr = 1e-10\n","    sigma_rw = np.sqrt((v2 - 2*sigma_mr**2) / 2)\n","\n","    return rho, sigma_mr, sigma_rw\n","\n","def train_kf(spread, rho, sigma_mr, sigma_rw):\n","    beta = np.polyfit(spread, np.roll(spread, 1), 1)[0]\n","    x_init = np.array([beta, sigma_mr, sigma_rw,])\n","    P_init = np.eye(3) * 0.1  # Regularized\n","    F = np.array([[1, 0, 0],\n","                  [0, rho, 0],\n","                  [0, 0, 1]])\n","    H = np.array([[1, 1, 1]])\n","    sigma_x = spread.var()\n","    Q = np.diag([sigma_x, sigma_mr, sigma_rw])\n","    R = np.array([[1e-10]])\n","    kf = KalmanFilter(transition_matrices=F,\n","                      observation_matrices=H,\n","                      transition_covariance=Q,\n","                      observation_covariance=R,\n","                      initial_state_mean=x_init,\n","                      initial_state_covariance=P_init)\n","    return kf, x_init, P_init\n","\n","def evaluate_kf(spread, rho, sigma_mr, sigma_rw, kf=None):\n","    if kf is None:\n","        kf, x, P = train_kf(spread, rho, sigma_mr, sigma_rw)\n","    else:\n","        x, P = kf.filter(spread)\n","        x = x[-1]\n","        P = P[-1]\n","\n","    # Arrays to store the results\n","    predicted_spread = []\n","    predicted_uncertainty = []\n","    for t in tqdm(range(len(spread)), desc=\"evaluate_kf\"):\n","        z = spread.iloc[t]\n","        x, P = kf.filter_update(filtered_state_mean=x, filtered_state_covariance=P, observation=z)\n","\n","        predicted_spread.append(x[0])\n","        predicted_uncertainty.append(P[0, 0])\n","\n","    return predicted_spread, kf\n","\n","window = abs(HALF_LIFE)\n","bb_df = signal_bollinger_bands(target_fut_df, f\"{TARGET_FUT}_Close\", window=window, std_factor=2.0)\n","spread = bb_df[\"%B\"].bfill().ffill()\n","\n","# Following the paper's estimations\n","p_rho, p_sigma_mr, p_sigma_rw = estimate_parameters(spread)\n","param_grid = {\n","    'rho': [p_rho],\n","    'sigma_mr': [p_sigma_mr],\n","    'sigma_rw': [p_sigma_rw],\n","}\n","best_params = [p_rho, p_sigma_mr, p_sigma_rw]\n","\n","def grid_search():\n","    tscv = TimeSeriesSplit(n_splits=2)\n","    best_score = float('inf')\n","    best_params = None\n","    param_combinations = list(itertools.product(param_grid['rho'], param_grid['sigma_mr'], param_grid['sigma_rw']))\n","    for params in tqdm(param_combinations, total=len(param_combinations), desc=\"Grid Search..\"):\n","        rho, sigma_mr, sigma_rw = params\n","        scores = []\n","        for train_index, val_index in tscv.split(spread):\n","            train_spread, val_spread = spread.iloc[train_index], spread.iloc[val_index]\n","            _, kf = evaluate_kf(train_spread, rho, sigma_mr, sigma_rw)\n","            predicted_spread, _ = evaluate_kf(val_spread, rho, sigma_mr, sigma_rw, kf)\n","            score = mean_squared_error(val_spread.values, predicted_spread)\n","            scores.append(score)\n","\n","        avg_score = np.mean(scores)\n","        if avg_score < best_score:\n","            best_score = avg_score\n","            best_params = params\n","\n","        print(f\"Best Params: {best_params}\")\n","        print(f\"Best Score: {best_score}\")\n","    return best_params, best_score"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["TRAIN_SIZE =  int(len(spread)*0.8)\n","VAL_SIZE = int(len(spread)*0.2)\n","\n","train_spread, val_spread = spread.iloc[:TRAIN_SIZE], spread.iloc[VAL_SIZE:]\n","rho, sigma_mr, sigma_rw = best_params\n","\n","kalman_gains = []\n","mean_reversion_errors = []\n","random_walk_errors = []\n","predicted_spread = []\n","predicted_uncertainty = []\n","\n","kf, x, P = train_kf(train_spread, rho, sigma_mr, sigma_rw)\n","for t in tqdm(range(len(val_spread)), desc=\"Validation\"):\n","    z = val_spread.iloc[t]\n","    x, P = kf.filter_update(filtered_state_mean=x, filtered_state_covariance=P, observation=z)\n","\n","    # K Gain for MR\n","    kalman_gain = np.dot(np.dot(P, kf.observation_matrices.T), np.linalg.inv(\n","        np.dot(np.dot(kf.observation_matrices, P), kf.observation_matrices.T) + kf.observation_covariance\n","    ))\n","    kalman_gains.append(kalman_gain[1,0])\n","    predicted_spread.append(x[0])\n","    predicted_uncertainty.append(P[0, 0])\n","    mean_reversion_errors.append( x[1])\n","    random_walk_errors.append(x[2])\n","\n","mse = mean_squared_error(val_spread.values, predicted_spread)\n","print(f'MSE {mse}') # BEST: 0.008108835479924673"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plotting the results\n","fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, gridspec_kw={'height_ratios': [3, 3, 1, 1]}, figsize=(18, 12))\n","\n","# Log Prices\n","ax1.plot(futs_df[f'{TARGET_FUT}_Close'].index[VAL_SIZE:], np.log(futs_df[f'{TARGET_FUT}_Close'].iloc[VAL_SIZE:]), label='Log Prices')\n","ax1.legend()\n","ax1.set_xlabel('Date')\n","ax1.set_ylabel('Log Prices')\n","ax1.set_title(f'{TARGET_FUT} Log Prices')\n","\n","# Actual vs Predicted Spread\n","ax2.plot(spread.index[VAL_SIZE:], spread[VAL_SIZE:], label='Actual Spread')\n","ax2.plot(spread.index[VAL_SIZE:], predicted_spread, label='Predicted Spread')\n","ax2.fill_between(spread.index[VAL_SIZE:],\n","                 np.array(predicted_spread) - np.sqrt(np.array(predicted_uncertainty)),\n","                 np.array(predicted_spread) + np.sqrt(np.array(predicted_uncertainty)),\n","                 color='gray', alpha=0.2, label='Uncertainty')\n","ax2.legend()\n","ax2.set_xlabel('Date')\n","ax2.set_ylabel('Spread')\n","ax2.set_title(f'{TARGET_FUT} Spread')\n","\n","# Component\n","ax3.plot(spread.index[VAL_SIZE:], mean_reversion_errors, label='Mean Reversion Error', color='green')\n","ax3.set_xlabel('Date')\n","ax3.set_ylabel('Mean Reversion Error', color='green')\n","ax3.tick_params(axis='y', labelcolor='green')\n","ax3.legend(loc='upper left')\n","ax3_2 = ax3.twinx()\n","ax3_2.plot(spread.index[VAL_SIZE:], random_walk_errors, label='Random Walk Error', color='red')\n","ax3_2.set_ylabel('Random Walk Error', color='red')\n","ax3_2.tick_params(axis='y', labelcolor='red')\n","ax3_2.legend(loc='upper right')\n","\n","# K Gain\n","ax4.plot(spread.index[VAL_SIZE:], kalman_gains, label='K Gain', color='yellow')\n","ax4.set_xlabel('Date')\n","ax4.set_ylabel('K Gain')\n","ax4.legend()\n","\n","plt.tight_layout()\n","plt.show()"]}],"metadata":{"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"datasetId":4755137,"sourceId":8061237,"sourceType":"datasetVersion"}],"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":4}
