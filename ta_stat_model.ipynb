{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"143f9c02-8d86-484a-b4c2-eb1317289f2a","_uuid":"068dcfb3-c368-468d-8410-aea88bc0b181","id":"oaDoHbxVH0CW"},"source":["# Statistical Algos"]},{"cell_type":"markdown","metadata":{"_cell_guid":"b5ba98a0-9590-4ccd-b238-cfae63d19770","_uuid":"6a6076dd-8ce5-47e2-8913-74dcaa2eacf0","id":"z_cBqdYOoY5S"},"source":["## Notebook's Environment"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"44c8b09f-6f40-410d-aa3c-89b119fb2456","_uuid":"56c0c199-418e-4fa2-a71a-30d54c3a8b2c","collapsed":false,"id":"eETPYJLiMU-b","jupyter":{"outputs_hidden":false},"outputId":"49f77cf0-e6a3-44d8-9dae-05a929fa4804","trusted":true},"outputs":[],"source":["INSTALL_DEPS = False\n","if INSTALL_DEPS:\n","  %pip install matplotlib==3.8.3\n","  %pip installnumpy==1.26.4\n","  %pip installpandas==2.2.1\n","  %pip installpandas_market_calendars==4.4.0\n","  %pip installpytz==2024.1\n","  %pip installscipy==1.12.0\n","  %pip installta==0.11.0\n","  %pip installyfinance==0.2.37\n","\n","!python --version"]},{"cell_type":"markdown","metadata":{},"source":["## Cloud Environment Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cf2e55fb-0872-49df-ae06-aa49505f9474","_uuid":"ccc8fcee-37e2-48b5-8501-6285d13e13cd","collapsed":false,"id":"Q4-GoceIIfT_","jupyter":{"outputs_hidden":false},"outputId":"7dcb11f2-d20e-4714-e4fe-f9895dc22aac","trusted":true},"outputs":[],"source":["import os\n","import sys\n","import warnings\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","IN_KAGGLE = IN_COLAB = False\n","try:\n","    # https://www.tensorflow.org/install/pip#windows-wsl2\n","    import google.colab\n","    from google.colab import drive\n","\n","    drive.mount(\"/content/drive\")\n","    DATA_PATH = \"/content/drive/MyDrive/EDT dataset\"\n","    MODEL_PATH = \"/content/drive/MyDrive/models\"\n","    IN_COLAB = True\n","    print(\"Colab!\")\n","except:\n","    IN_COLAB = False\n","if \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ and not IN_COLAB:\n","    print(\"Running in Kaggle...\")\n","    for dirname, _, filenames in os.walk(\"/kaggle/input\"):\n","        for filename in filenames:\n","            print(os.path.join(dirname, filename))\n","    MODEL_PATH = \"./models\"\n","    DATA_PATH = \"/kaggle/input/\"\n","    IN_KAGGLE = True\n","    print(\"Kaggle!\")\n","elif not IN_COLAB:\n","    IN_KAGGLE = False\n","    MODEL_PATH = \"./models\"\n","    DATA_PATH = \"./data/\"\n","    print(\"running localhost!\")"]},{"cell_type":"markdown","metadata":{},"source":["# Instruments"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from constants import *\n","\n","INTERVAL = YFinanceOptions.M15\n","TARGET_FUT, INTERVAL"]},{"cell_type":"markdown","metadata":{},"source":["## Data Load"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","filename = f\"{DATA_PATH}{os.sep}futures_{INTERVAL}.csv\"\n","print(filename)\n","futs_df = pd.read_csv(filename, index_col=\"Date\", parse_dates=True)\n","\n","print(futs_df.shape)\n","print(futs_df.columns)\n","futs_df.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(18, 8))\n","\n","plt.plot(futs_df[f'{TARGET_FUT}_Close'], label=f'{TARGET_FUT} Close', alpha=0.7)\n","plt.title(f'{TARGET_FUT} Price')\n","plt.xlabel('Date')\n","plt.ylabel('Price')\n","plt.legend()\n","plt.grid(True)\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["target_fut_df = futs_df[[f\"{TARGET_FUT}_Close\", f\"{TARGET_FUT}_Volume\"]]\n","target_fut_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from quant_equations import get_ou, get_annualized_factor, calc_annualized_sharpe, deflated_sharpe_ratio, modulate_std\n","\n","HALF_LIFE, HURST = get_ou(target_fut_df, f\"{TARGET_FUT}_Close\")\n","\n","print(\"Half-Life:\", HALF_LIFE)\n","print(\"Hurst:\", HURST)"]},{"cell_type":"markdown","metadata":{},"source":["# Kalman Filter"]},{"cell_type":"markdown","metadata":{},"source":["The Kalman filter consists of states, observations, and transitions.\n","\n","$$\n","X_t = H_t Z_t + V_t\n","$$\n","\n","$$\n","Z_t = F_{t-1} Z_{t-1} + G_{t-1} U_{t-1} + W_{t-1}\n","$$\n","\n","- $ Z_t $ is the unobservable state, mapped by $ H_t $ to $ X_t $, representing the internal hidden states.\n","- $ X_t $ is the price.\n","- $ U_t $ are the control parameters, which are 0 in this case. $ G_t $ links $ U_t $ to $ Z_t $, which is also 0.\n","- $ F_{t-1} $ is the state transition matrix.\n","- $ W_t $ and $ V_t $ are the noise terms with covariance matrices $ Q_t $ and $ R_t $, respectively.\n","\n","The model equations:\n","\n","1. **Prediction of the Error Covariance:**\n","$$\n","P_t = F_{t-1} P_{t-1}^+ F_{t-1}^T + Q_{t-1}\n","$$\n","   - Predicts the new error covariance $ P_t $, representing the accuracy of the next prediction.\n","   - $ Q_{t-1} $ is the process noise covariance.\n","   - $ F_{t-1} $ is the state transition matrix.\n","   - $ P_{t-1} $ is the previous error covariance.\n","\n","2. **Update of the Error Covariance:**\n","$$\n","P_t^+ = (I - K_t H_t) P_t (I - K_t H_t)^T + K_t R_t K_t^T\n","$$\n","   - Updates the error covariance.\n","   - $ P_t^+ $ is the new level of uncertainty.\n","   - $ K_t $ is the Kalman gain.\n","   - $ H_t $ is the observation matrix.\n","   - $ R_t $ is the observation noise covariance.\n","   - $ I $ is the identity matrix.\n","\n","3. **Kalman Gain:**\n","$$\n","K_t = P_t H_t^T (H_t P_t H_t^T + R_t)^{-1}\n","$$\n","   - The gain matrix that determines the correction applied to the prediction.\n","   - A small gain indicates low uncertainty in the observation $ X_t $.\n","\n","4. **State Prediction:**\n","$$\n","Z_t^- = F_{t-1} Z_{t-1}^+ + G_{t-1} U_{t-1}\n","$$\n","   - Predicts the next state from the previous corrected state $ Z_{t-1}^+ $, using the state transition matrix $ F_{t-1} $.\n","   - $ G_{t-1} U_{t-1} $ represents the control input, which is 0 in this case.\n","\n","5. **State Update:**\n","$$\n","Z_t^+ = Z_t^- + K_t (X_t - H_t Z_t^-) = Z_t^- (1 - K_t H_t) + K_t X_t\n","$$\n","   - Updates the state $ Z_t^+ $ after incorporating the new observation $ X_t $.\n","   - $ X_t - H_t Z_t^- $ is the residual (or innovation), representing the difference between the observed and predicted values.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Kalman no-lookback MA\n","\n","\n","$$\n","y(t) = m(t) + \\epsilon(t), \\quad \\text{(\"Measurement\")} \n","$$\n","\n","$$\n","m(t) = m(t-1) + \\omega(t-1). \\quad \\text{(\"State transition\")}\n","$$\n","\n","\n","\n","$$\n","m(t \\mid t) = m(t \\mid t-1) + K(t) (y(t) - m(t \\mid t-1)). \\quad \\text{(\"State update\")}\n","$$\n","\n","\n","\n","Variance of the Forecast Error\n","$$\n","Q(t) = \\text{var}(m(t)) + V_{\\epsilon}. \\tag{3.17}\n","$$\n","\n","\n","The **Kalman gain** is\n","$$\n","K(t) = \\frac{R(t \\mid t-1)}{R(t \\mid t-1) + V_{\\epsilon}}, \\tag{3.18}\n","$$\n","\n","\n","and the state variance update is\n","\n","$$\n","R(t \\mid t) = (1 - K(t)) R(t \\mid t-1). \\tag{3.19}\n","$$\n","\n","Uncertainty:\n","$$\n","V_{\\epsilon} = R(t \\mid t-1) \\left( \\frac{\\tau}{T_{\\text{max}} - 1} \\right) \\tag{3.20}\n","$$"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from signals import signal_kf_bollinger_bands\n","\n","\n","window = abs(HALF_LIFE)\n","bb_df = signal_kf_bollinger_bands(target_fut_df, f\"{TARGET_FUT}_Close\", f\"{TARGET_FUT}_Volume\", std_factor=modulate_std (HURST))\n","spread = bb_df[\"%B\"].bfill().ffill()\n","volumes = target_fut_df[f\"{TARGET_FUT}_Volume\"].to_numpy() # Keep uncertainty unscaled, i want it to impact more.\n","\n","assert not np.isnan(spread).any() and not np.isnan(volumes).any()\n","\n","bb_df.tail(5)"]},{"cell_type":"markdown","metadata":{},"source":["## Visualize KF BB"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(18, 14))\n","\n","# To make the plots easier to read\n","ZOOM = 200\n","bb_df = bb_df.tail(ZOOM)\n","\n","# Plot for price and Bollinger Bands\n","ax1 = plt.subplot2grid((18, 1), (0, 0), rowspan=8, colspan=1)\n","ax1.plot(bb_df[f'{TARGET_FUT}_Close'], label=f'{TARGET_FUT} Close', color='blue', alpha=0.6, linestyle='--')\n","ax1.plot(bb_df['MA'], label='Moving Average', color='red', linestyle='-.')\n","ax1.plot(bb_df['U'], label='Upper Bollinger Band', color='green')\n","ax1.plot(bb_df['L'], label='Lower Bollinger Band', color='green', alpha=0.7)\n","ax1.set_title(f'Bollinger Bands for {TARGET_FUT}')\n","ax1.set_xlabel('Date')\n","ax1.set_ylabel('Price')\n","ax1.legend()\n","ax1.grid(True)\n","\n","# Plot for volume\n","ax2 = plt.subplot2grid((18, 1), (8, 0), rowspan=4, colspan=1, sharex=ax1)\n","ax2.bar(bb_df.index, bb_df[f'{TARGET_FUT}_Volume'], label=f'{TARGET_FUT} Volume', color='grey')\n","ax2.set_title(f'Volume for {TARGET_FUT}')\n","ax2.set_xlabel('Date')\n","ax2.set_ylabel('Volume')\n","ax2.legend()\n","ax2.grid(True)\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Backtest"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from tqdm import tqdm\n","import itertools\n","import math\n","from scipy.stats import skew, kurtosis\n","\n","def bollinger_band_backtest(price_df, target_col, volume_col, std_factor, stoploss_pct=0.9, t_max=0.1):\n","    df = price_df.copy()\n","    bb_df = signal_kf_bollinger_bands(df, target_col, volume_col, std_factor, t_max=t_max)\n","\n","    df['MA'] = bb_df['MA']\n","    df['SD'] = bb_df['SD']\n","    df['U'] = bb_df['U']\n","    df['L'] = bb_df['L']\n","    df['SB'] = (df[target_col] < bb_df['L']).astype(int).diff().clip(0) * +1\n","    df['SS'] = (df[target_col] > bb_df['U']).astype(int).diff().clip(0) * -1\n","    df['SBS'] = (df[target_col] > bb_df['MA']).astype(int).diff().clip(0) * -1\n","    df['SSB'] = (df[target_col] < bb_df['MA']).astype(int).diff().clip(0) * +1\n","    df['Closed'] = 0\n","    df['Position'] = 0\n","    df['Ret'] = 0.\n","    entry = position = 0\n","    for i, row in df.iterrows():\n","        if (row['SBS'] == -1 and position == 1) or \\\n","            (row['SSB'] == 1 and position == -1) or \\\n","            (position == 1 and row[target_col] <= row[target_col] - (stoploss_pct * entry)) or \\\n","            (position == -1 and row[target_col] >= row[target_col] + (stoploss_pct * entry)):\n","            if position == 1:\n","                df.loc[i, 'Ret'] = (row[target_col] - entry) / entry\n","                df.loc[i, 'Closed'] = 1\n","            else:\n","                df.loc[i, 'Ret'] = (entry - row[target_col]) / entry\n","                df.loc[i, 'Closed'] = -1\n","            position = 0\n","\n","        if (row['SB'] == 1 and position == 0) or (row['SS'] == -1 and position == 0):\n","            entry = row[target_col]\n","            position = 1 if row['SB'] == 1 else -1\n","        df.loc[i, 'Position'] = position\n","        # TODO: add unrealized returns to check for DDs.\n","\n","    df['cRets'] = (1 + df['Ret']).cumprod() - 1\n","\n","    variance = df['Ret'].var()\n","    df['Drawdown'] = (1 + df['Ret']).cumprod().div((1 + df['Ret']).cumprod().cummax()) - 1\n","    max_drawdown = df['Drawdown'].min()\n","    drawdown_length = (df['Drawdown'] < 0).astype(int).groupby(df['Drawdown'].eq(0).cumsum()).cumsum().max()\n","    sharpe = calc_annualized_sharpe(df['Ret'], period=INTERVAL)\n","    trades = (df['Position'].diff().ne(0) & df['Position'].ne(0)).sum()\n","    stats_df = pd.DataFrame({\n","        \"T_max\": [t_max],\n","        \"Standard_Factor\": [std_factor],\n","        \"stoploss_pct\": [stoploss_pct],\n","        \"Cumulative_Returns\": [df['cRets'].iloc[-1]],\n","        \"Max Ret\": [df['Ret'].max()],\n","        \"Max Loss\": [df['Ret'].min()],\n","        \"Variance\": [variance],\n","        \"STD\": [np.sqrt(variance)],\n","        \"Max_Drawdown\": [max_drawdown],\n","        \"Drawdown_Length\": [drawdown_length],\n","        \"Sharpe\": [sharpe],\n","        \"Trades_Count\": [trades],\n","        \"Trades_per_Interval\": [trades / len(df)],\n","        \"Trading_Intervals\": [len(df)],\n","        \"Rets\": [df['Ret'].to_numpy()],\n","        \"Rets_Skew\": [skew(df['Ret'].to_numpy())],\n","        \"Rets_Kurt\": [kurtosis(df['Ret'].to_numpy())],\n","    })\n","\n","    return df, stats_df\n","\n","def param_search_bbs(df, target_col, volume_col, hurst=HURST):\n","    std_adjustments = [0.05, 0.25, 0.5]\n","    t_maxs = [0.1, 0.5, 0.9]\n","    combinations = list(itertools.product(t_maxs, std_adjustments))\n","\n","    best_sharpe = -float('inf')\n","    best_sharpe_stats = None\n","    best_rets = -float('inf')\n","    best_rets_stats = None\n","    best_mdd = -float('inf')\n","    best_mdd_stats = None\n","\n","    sharpes = []\n","    n_tests = len(combinations)\n","\n","    for t_max, adjustment in tqdm(combinations, desc=\"param_search_bbs\"):\n","        std_factor = modulate_std(hurst, adjustment=adjustment)\n","        _, stats_df = bollinger_band_backtest(df, target_col, volume_col, std_factor, t_max=t_max)\n","\n","        stat = stats_df['Sharpe'].iloc[0]\n","        sharpes.append(stat)\n","        if stat > best_sharpe:\n","            best_sharpe = stat\n","            best_sharpe_stats = stats_df.copy()\n","\n","        stat = stats_df['Cumulative_Returns'].iloc[0]\n","        if stat > best_rets:\n","            best_rets = stat\n","            best_rets_stats = stats_df.copy()\n","\n","        stat = stats_df['Max_Drawdown'].iloc[0]\n","        if stat > best_mdd:\n","            best_mdd = stat\n","            best_mdd_stats = stats_df.copy()\n","\n","    # We're datamining, we need to deflated the sharpe!\n","    for df in [best_sharpe_stats, best_rets_stats, best_mdd_stats]:\n","        df['Sharpe'] = deflated_sharpe_ratio(df['Sharpe'].iloc[0],\n","                                            len(df['Rets'].iloc[0]),\n","                                            df['Rets_Skew'].iloc[0],\n","                                            df['Rets_Kurt'].iloc[0],\n","                                            sharpes,\n","                                            n_tests)\n","\n","    results_df = pd.concat([best_sharpe_stats.assign(Metric='Sharpe'),\n","                            best_rets_stats.assign(Metric='Cumulative Returns'),\n","                            best_mdd_stats.assign(Metric='Max Drawdown')],\n","                           ignore_index=True)\n","\n","    return results_df\n","\n","\n","stats_df = param_search_bbs(futs_df, f'{TARGET_FUT}_Close', f'{TARGET_FUT}_Volume', hurst=HURST)\n","cumret_df= stats_df[stats_df[\"Metric\"] == \"Cumulative Returns\"]\n","cumret_df.drop(columns=[\"Rets\"])"]},{"cell_type":"markdown","metadata":{},"source":["# KF"]},{"cell_type":"markdown","metadata":{},"source":["$$ x(t+1) = x(t) + \\omega(t)$$ \n","\n","where $ x(t) $ is the stock close price at time $ t $ with a normal distribution $ N(\\mu_t, P_t) $ and $ \\omega(t) $ is the process model distributed as $ N(0, Q_t) $. \n","\n","The spread between consecutive close observables is a white noise with a time varying variance.\n","\n","The measurement $ z(t) $ would be the observed daily close price. \n","Because there is no uncertainty, we can interpret the measurement noise, $ N(0, R_t) $, as the belief that the observed price is meaningful. If the observed price has a large impact on future observables, i.e., if $R_t$ is small, then the Kalman filter would update our prediction to be closer to the observed price. Conversely, if we are not sure, i.e., if $ R_t $ is large, then the observed price won't be used to augment our prediction. \n","\n","Assuming that a close price with a large trading volume compared to the previous day is more likely to affect the next day's price:\n","\n","$$\n","R_t = P_t \\ast \\frac{V_{t-1}}{\\min(V_{t-1}, V_t)}\n","$$\n","\n","where $ V_t $ is the daily trading volume at day $ t $.(Sinclair, 2010).\n","\n","Init:\n","- $\\mu_0 = z(0)$: The last close price on the first daily.\n","- $P_0$: The variance of  the least interval.\n","- Qt of process model $w(t)$ as $Q_0 = \\frac{\\sigma}{1-\\sigma}$, where $\\sigma$ is $10^{-4}$ (Chan. 2013)"]},{"cell_type":"markdown","metadata":{},"source":["https://thescipub.com/pdf/jcssp.2023.739.748.pdf\n","\n","For a system with position, velocity, and acceleration, the state transition matrix can be derived from the kinematic equations.\n","Assuming a discrete-time system with constant time step $ \\Delta t $:\n","- Position (price) $ x_t $\n","- Velocity (speed) $ v_t $\n","- Acceleration $ a_t $\n","\n","The state vector $ Z_t $ is:\n","\n","$$\n","Z_t = \\begin{bmatrix} x_t \\\\ v_t \\\\ a_t \\end{bmatrix}\n","$$\n","\n","The kinematic equations for constant acceleration are:\n","\n","$$\n","x_{t+1} = x_t + v_t \\Delta t + \\frac{1}{2} a_t \\Delta t^2\n","$$\n","\n","$$\n","v_{t+1} = v_t + a_t \\Delta t\n","$$\n","\n","$$\n","a_{t+1} = a_t \\quad \\text{(assuming acceleration remains constant over the time step)}\n","$$\n","\n","These equations can be represented in matrix form as:\n","\n","$$\n","\\begin{bmatrix} x_{t+1} \\\\ v_{t+1} \\\\ a_{t+1} \\end{bmatrix} = \\begin{bmatrix} 1 & \\Delta t & \\frac{1}{2} \\Delta t^2 \\\\ 0 & 1 & \\Delta t \\\\ 0 & 0 & 1 \\end{bmatrix} \\begin{bmatrix} x_t \\\\ v_t \\\\ a_t \\end{bmatrix}\n","$$\n","\n","Thus, the state transition matrix $ F $ is:\n","\n","$$\n","F = \\begin{bmatrix} 1 & \\Delta t & \\frac{1}{2} \\Delta t^2 \\\\ 0 & 1 & \\Delta t \\\\ 0 & 0 & 1 \\end{bmatrix}\n","$$\n","\n","The observation matrix $ H $ maps the state vector $ Z_t $ to the observation $ X_t $.\n","\n","Since the \\%B measure directly relates to the position component of the state vector, the observation matrix $ H $ is:\n","$$\n","H = \\begin{bmatrix} 1 & 0 & 0 \\end{bmatrix}\n","$$\n","\n","This means that the observed \\%B measure is a direct observation of the position without direct observation of velocity or acceleration.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import mean_squared_error\n","from pykalman import KalmanFilter\n","\n","def signal_kf(observables, volumes, em_train_perc=0.80, em_iter=15, delta_t=1, q_t=0.0001, r_t=0.1):\n","    # State transition matrix\n","    train_size = int(len(observables) * em_train_perc)\n","    F = np.array([\n","        [1, delta_t, 0.5 * delta_t**2],\n","        [0, 1, delta_t],\n","        [0, 0, 1]\n","    ])\n","    # Observation matrix\n","    H = np.array([[1, 0, 0]])\n","    # Initial values don't have that much affect down the line.\n","    initial_x = np.mean(observables[:train_size])\n","    initial_var = np.var(observables[:train_size])\n","    state_mean = np.array([initial_x, 0, 0])\n","    # https://pykalman.github.io/\n","    kf = KalmanFilter(\n","        transition_matrices=F,\n","        observation_matrices=H,\n","        initial_state_mean=state_mean,  # initial velocity and acceleration are zero\n","        initial_state_covariance=np.eye(3) * initial_var,  # Covariance matrix for the state\n","        observation_covariance=np.array([[r_t]]),  # Observation Noise.\n","        transition_covariance=np.eye(3) * q_t,  # Q, Process Noise.\n","        em_vars=['transition_covariance', 'observation_covariance',\n","                 'initial_state_mean', 'initial_state_covariance']\n","    )\n","\n","    # 'Train'. EM to find the best Model Var\n","    kf = kf.em(observables[:train_size], n_iter=em_iter)\n","    filtered_state_means, filtered_state_covariances = kf.filter(observables[:train_size])\n","    state_mean = filtered_state_means[-1]\n","    state_covariance = filtered_state_covariances[-1]\n","\n","    filtered_state_means = []\n","    hidden_1 = []\n","    hidden_2 = []\n","    filtered_state_covariances = []\n","    kalman_gains = []\n","\n","    filtered_state_means.append(state_mean[0])\n","    for i in tqdm(range(train_size, len(observables))):\n","        # Rt = Pt * Vt-1 / min(Vt-1, Vt)\n","        if volumes[i-1] != 0 and volumes[i] != 0:\n","            Rt = state_covariance[0, 0] * volumes[i-1] / min(volumes[i-1], volumes[i])\n","        else:\n","            Rt = state_covariance[0, 0]\n","        assert not np.isnan(Rt).any(), f\"{Rt} = {state_covariance[0, 0] } * {volumes[i-1]} / {min(volumes[i-1], volumes[i])} at {i}\"\n","\n","        # Predict step\n","        means, states = kf.filter(observables[:i])\n","        state_mean = means[-1]\n","        state_covariance = states[-1]\n","\n","        state_mean, state_covariance = kf.filter_update(\n","            filtered_state_mean=state_mean,\n","            filtered_state_covariance=state_covariance,\n","            observation=np.array([observables[i]]),\n","            observation_matrix=H,\n","            observation_covariance=np.array([[Rt]])\n","        )\n","\n","        kalman_gain = state_covariance @ H.T @ np.linalg.inv(H @ state_covariance @ H.T + np.array([[Rt]]))\n","        kalman_gains.append(kalman_gain[:, 0])\n","        filtered_state_means.append(state_mean[0])\n","        filtered_state_covariances.append(state_covariance[0, 0])\n","        hidden_1.append(state_mean[1])\n","        hidden_2.append(state_mean[2])\n","\n","    # Align with the observations\n","    filtered_state_means = filtered_state_means[:-delta_t]\n","    residuals = observables[train_size:] - np.array(filtered_state_means)\n","\n","    results = pd.DataFrame({\n","        'X': observables[train_size:].values,\n","        'Z1': hidden_1,\n","        'Z2': hidden_2,\n","        'Filtered_X': filtered_state_means,\n","        'Uncertainty': filtered_state_covariances,\n","        'Residuals': residuals,\n","        'KG_X': [kg[0] for kg in kalman_gains],\n","        'KG_Z1': [kg[1] for kg in kalman_gains],\n","        'KG_Z2': [kg[2] for kg in kalman_gains]\n","    })\n","\n","    return results\n","\n","results = signal_kf(spread, volumes=volumes)\n","mse = mean_squared_error(results['X'], results['Filtered_X'])\n","print(f'MSE {mse}')\n","results.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Visuals"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","fig, axs = plt.subplots(5, gridspec_kw={'height_ratios': [3, 3, 1, 1, 1]}, figsize=(18, 16))\n","\n","# Plot the future's close prices\n","axs[0].plot(futs_df.index[-len(results['X']):], futs_df[f'{TARGET_FUT}_Close'].tail(len(results['X'])), label='Future Close', color='blue')\n","axs[0].set_title(f'{TARGET_FUT} Close Prices')\n","axs[0].legend()\n","\n","# Plot the actual vs filtered observables with uncertainty tunnel\n","axs[1].plot(results.index, results['X'], label='Actual Spread', linestyle=\"-.\")\n","axs[1].plot(results.index, results['Filtered_X'], label='Kalman Filtered Spread', alpha=0.7)\n","axs[1].fill_between(results.index,\n","                    results['Filtered_X'] - results['Uncertainty'],\n","                    results['Filtered_X'] + results['Uncertainty'],\n","                    label='Uncertainty', color=\"gray\", alpha=0.5)\n","axs[1].set_title(f'{TARGET_FUT} Actual vs Kalman Filtered Spread')\n","axs[1].legend()\n","axs[1].set_ylim(-0.5,2)\n","\n","# Plot the residuals\n","axs[2].plot(results.index, results['Z1'], label='Hidden 1')\n","axs[2].plot(results.index, results['Z2'], label='Hidden 2', alpha=0.7)\n","axs[2].set_title(f'{TARGET_FUT} Kalman Filter Residuals')\n","axs[2].axhline(y=0, color='black', linestyle='--')\n","axs[2].legend()\n","\n","# Plot the residuals\n","axs[3].plot(results.index, results['Residuals'], label='Residuals', color='red')\n","axs[3].set_title(f'{TARGET_FUT} Kalman Filter Residuals')\n","axs[3].axhline(y=0, color='black', linestyle='--')\n","axs[3].legend()\n","\n","# Kalman Gain\n","axs[4].bar(results.index, results['KG_X'], label='Measure')\n","axs[4].bar(results.index, results['KG_Z1'], label='Hidden 1')\n","axs[4].bar(results.index, results['KG_Z2'], label='Hidden 2')\n","axs[4].set_title(f'{TARGET_FUT} Kalman Gain')\n","axs[4].legend()\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Backtests"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from scipy.stats import skew, kurtosis\n","\n","def kalman_backtest(observables, volumes, thresholds=[0, 0.5, 1], stoploss_pct=0.5, delta_t=1, q_t=0.00010001000100010001, em_train_perc=0.2, em_iter=15):\n","    results = signal_kf(observables, volumes, em_train_perc, em_iter, delta_t, q_t)\n","    df = results.copy()\n","\n","    df['SB'] = (df['Filtered_X'] <= thresholds[0]).astype(int).diff().clip(0) * +1\n","    df['SS'] = (df['Filtered_X'] >= thresholds[2]).astype(int).diff().clip(0) * -1\n","    df['SBS'] = (df['Filtered_X'] >= thresholds[1]).astype(int).diff().clip(0) * -1\n","    df['SSB'] = (df['Filtered_X'] <= thresholds[1]).astype(int).diff().clip(0) * +1\n","    df['Closed'] = 0\n","    df['Position'] = 0\n","    df['Ret'] = 0.0\n","    entry = position = 0\n","    target_col = 'X'\n","    for i, row in tqdm(df.iterrows(), desc=\"kalman_backtest\"):\n","        if (row['SBS'] == -1 and position == 1) or \\\n","           (row['SSB'] == 1 and position == -1) or \\\n","           (position == 1 and row[target_col] <= entry * (1 - stoploss_pct)) or \\\n","           (position == -1 and row[target_col] >= entry * (1 + stoploss_pct)):\n","            if position == 1:\n","                df.loc[i, 'Ret'] = (row[target_col] - entry) / entry\n","                df.loc[i, 'Closed'] = 1\n","            else:\n","                df.loc[i, 'Ret'] = (entry - row[target_col]) / entry\n","                df.loc[i, 'Closed'] = -1\n","            position = 0\n","\n","        if (row['SB'] == 1 and position == 0) or (row['SS'] == -1 and position == 0):\n","            entry = row[target_col]\n","            position = 1 if row['SB'] == 1 else -1\n","        df.loc[i, 'Position'] = position\n","\n","    df['cRets'] = (1 + df['Ret']).cumprod() - 1\n","\n","    variance = df['Ret'].var()\n","    df['Drawdown'] = (1 + df['Ret']).cumprod().div((1 + df['Ret']).cumprod().cummax()) - 1\n","    max_drawdown = df['Drawdown'].min()\n","    drawdown_length = (df['Drawdown'] < 0).astype(int).groupby(df['Drawdown'].eq(0).cumsum()).cumsum().max()\n","    sharpe = calc_annualized_sharpe(df['Ret'], period=INTERVAL)\n","    trades = (df['Position'].diff().ne(0) & df['Position'].ne(0)).sum()\n","    stats_df = pd.DataFrame({\n","        \"Thresholds\": [thresholds],\n","        \"Stoploss_pct\": [stoploss_pct],\n","        \"Cumulative_Returns\": [df['cRets'].iloc[-1]],\n","        \"Max Ret\": [df['Ret'].max()],\n","        \"Max Loss\": [df['Ret'].min()],\n","        \"Variance\": [variance],\n","        \"STD\": [np.sqrt(variance)],\n","        \"Max_Drawdown\": [max_drawdown],\n","        \"Drawdown_Length\": [drawdown_length],\n","        \"Sharpe\": [sharpe],\n","        \"Trades_Count\": [trades],\n","        \"Trades_per_Interval\": [trades / len(df)],\n","        \"Trading_Intervals\": [len(df)],\n","        \"Rets\": [df['Ret'].to_numpy()],\n","        \"Rets_Skew\": [skew(df['Ret'].to_numpy())],\n","        \"Rets_Kurt\": [kurtosis(df['Ret'].to_numpy())],\n","    })\n","\n","    return df, stats_df\n","\n","df, stats_df = kalman_backtest(spread, volumes=volumes)\n","stats_df.drop(columns=[\"Rets\"])"]}],"metadata":{"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"datasetId":4755137,"sourceId":8061237,"sourceType":"datasetVersion"}],"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":4}
